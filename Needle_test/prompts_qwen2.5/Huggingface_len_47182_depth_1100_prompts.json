[{"role": "system", "content": "You are a helpful AI bot that answers questions for a user. Keep your response short and direct"}, {"role": "user", "content": "December 2019There are two distinct ways to be politically moderate: on purpose\nand by accident. Intentional moderates are trimmers, deliberately\nchoosing a position mid-way between the extremes of right and left.\nAccidental moderates end up in the middle, on average, because they\nmake up their own minds about each question, and the far right and\nfar left are roughly equally wrong.You can distinguish intentional from accidental moderates by the\ndistribution of their opinions. If the far left opinion on some\nmatter is 0 and the far right opinion 100, an intentional moderate's\nopinion on every question will be near 50. Whereas an accidental\nmoderate's opinions will be scattered over a broad range, but will,\nlike those of the intentional moderate, average to about 50.Intentional moderates are similar to those on the far left and the\nfar right in that their opinions are, in a sense, not their own.\nThe defining quality of an ideologue, whether on the left or the\nright, is to acquire one's opinions in bulk. You don't get to pick\nand choose. Your opinions about taxation can be predicted from your\nopinions about sex. And although intentional moderates\nmight seem to be the opposite of ideologues, their beliefs (though\nin their case the word \"positions\" might be more accurate) are also\nacquired in bulk. If the median opinion shifts to the right or left,\nthe intentional moderate must shift with it. Otherwise they stop\nbeing moderate.Accidental moderates, on the other hand, not only choose their own\nanswers, but choose their own questions. They may not care at all\nabout questions that the left and right both think are terribly\nimportant. So you can only even measure the politics of an accidental\nmoderate from the intersection of the questions they care about and\nthose the left and right care about, and this can\nsometimes be vanishingly small.It is not merely a manipulative rhetorical trick to say \"if you're\nnot with us, you're against us,\" but often simply false.Moderates are sometimes derided as cowards, particularly by \nthe extreme left. But while it may be accurate to call intentional\nmoderates cowards, openly being an accidental moderate requires the\nmost courage of all, because you get attacked from both right and\nleft, and you don't have the comfort of being an orthodox member\nof a large group to sustain you.Nearly all the most impressive people I know are accidental moderates.\nIf I knew a lot of professional athletes, or people in the entertainment\nbusiness, that might be different. Being on the far left or far\nright doesn't affect how fast you run or how well you sing. But\nsomeone who works with ideas has to be independent-minded to do it\nwell.Or more precisely, you have to be independent-minded about the ideas\nyou work with. You could be mindlessly doctrinaire in your politics\nand still be a good mathematician. In the 20th century, a lot of\nvery smart people were Marxists \u0097 just no one who was smart about\nthe subjects Marxism involves. But if the ideas you use in your\nwork intersect with the politics of your time, you have two choices:\nbe an accidental moderate, or be mediocre.Notes[1] It's possible in theory for one side to be entirely right and\nthe other to be entirely wrong. Indeed, ideologues must always\nbelieve this is the case. But historically it rarely has been.[2] For some reason the far right tend to ignore moderates rather\nthan despise them as backsliders. I'm not sure why. Perhaps it\nmeans that the far right is less ideological than the far left. Or\nperhaps that they are more confident, or more resigned, or simply\nmore disorganized. I just don't know.[3] Having heretical opinions doesn't mean you have to express\nthem openly. It may be\neasier to have them if you don't.\nThanks to Austen Allred, Trevor Blackwell, Patrick Collison, Jessica Livingston,\nAmjad Masad, Ryan Petersen, and Harj Taggar for reading drafts of this.\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nJuly 2004(This essay is derived from a talk at Oscon 2004.)\nA few months ago I finished a new \nbook, \nand in reviews I keep\nnoticing words like \"provocative'' and \"controversial.'' To say\nnothing of \"idiotic.''I didn't mean to make the book controversial.  I was trying to make\nit efficient.  I didn't want to waste people's time telling them\nthings they already knew.  It's more efficient just to give them\nthe diffs.  But I suppose that's bound to yield an alarming book.EdisonsThere's no controversy about which idea is most controversial:\nthe suggestion that variation in wealth might not be as big a\nproblem as we think.I didn't say in the book that variation in wealth was in itself a\ngood thing.  I said in some situations it might be a sign of good\nthings.  A throbbing headache is not a good thing, but it can be\na sign of a good thing-- for example, that you're recovering\nconsciousness after being hit on the head.Variation in wealth can be a sign of variation in productivity.\n(In a society of one, they're identical.) And that\nis almost certainly a good thing: if your society has no variation\nin productivity, it's probably not because everyone is Thomas\nEdison.  It's probably because you have no Thomas Edisons.In a low-tech society you don't see much variation in productivity.\nIf you have a tribe of nomads collecting sticks for a fire, how\nmuch more productive is the best stick gatherer going to be than\nthe worst?  A factor of two?  Whereas when you hand people a complex tool\nlike a computer, the variation in what they can do with\nit is enormous.That's not a new idea.  Fred Brooks wrote about it in 1974, and\nthe study he quoted was published in 1968.  But I think he\nunderestimated the variation between programmers.  He wrote about productivity in lines\nof code:  the best programmers can solve a given problem in a tenth\nthe time.  But what if the problem isn't given? In programming, as\nin many fields, the hard part isn't solving problems, but deciding\nwhat problems to solve.  Imagination is hard to measure, but\nin practice it dominates the kind of productivity that's measured\nin lines of code.Productivity varies in any field, but there are few in which it\nvaries so much.  The variation between programmers\nis so great that it becomes a difference in kind.  I don't\nthink this is something intrinsic to programming, though.  In every field,\ntechnology magnifies differences in productivity.  I think what's\nhappening in programming is just that we have a lot of technological\nleverage.  But in every field the lever is getting longer, so the\nvariation we see is something that more and more fields will see\nas time goes on.  And the success of companies, and countries, will\ndepend increasingly on how they deal with it.If variation in productivity increases with technology, then the\ncontribution of the most productive individuals will not only be\ndisproportionately large, but will actually grow with time.  When\nyou reach the point where 90% of a group's output is created by 1%\nof its members, you lose big if something (whether Viking raids,\nor central planning) drags their productivity down to the average.If we want to get the most out of them, we need to understand these\nespecially productive people.  What motivates them?  What do they\nneed to do their jobs?  How do you recognize them? How do you\nget them to come and work for you?  And then of course there's the\nquestion, how do you become one?More than MoneyI know a handful of super-hackers, so I sat down and thought about\nwhat they have in common.  Their defining quality is probably that\nthey really love to program.  Ordinary programmers write code to pay\nthe bills.  Great hackers think of it as something they do for fun,\nand which they're delighted to find people will pay them for.Great programmers are sometimes said to be indifferent to money.\nThis isn't quite true.  It is true that all they really care about\nis doing interesting work.  But if you make enough money, you get\nto work on whatever you want, and for that reason hackers are\nattracted by the idea of making really large amounts of money.\nBut as long as they still have to show up for work every day, they\ncare more about what they do there than how much they get paid for\nit.Economically, this is a fact of the greatest importance, because\nit means you don't have to pay great hackers anything like what\nthey're worth.  A great programmer might be ten or a hundred times\nas productive as an ordinary one, but he'll consider himself lucky\nto get paid three times as much.  As I'll explain later, this is\npartly because great hackers don't know how good they are.  But\nit's also because money is not the main thing they want.What do hackers want?  Like all craftsmen, hackers like good tools.\nIn fact, that's an understatement.  Good hackers find it unbearable\nto use bad tools.  They'll simply refuse to work on projects with\nthe wrong infrastructure.At a startup I once worked for, one of the things pinned up on our\nbulletin board was an ad from IBM.  It was a picture of an AS400,\nand the headline read, I think, \"hackers despise\nit.'' [1]When you decide what infrastructure to use for a project, you're\nnot just making a technical decision.  You're also making a social\ndecision, and this may be the more important of the two.  For\nexample, if your company wants to write some software, it might\nseem a prudent choice to write it in Java.  But when you choose a\nlanguage, you're also choosing a community.  The programmers you'll\nbe able to hire to work on a Java project won't be as\nsmart as the\nones you could get to work on a project written in Python.\nAnd the quality of your hackers probably matters more than the\nlanguage you choose.  Though, frankly, the fact that good hackers\nprefer Python to Java should tell you something about the relative\nmerits of those languages.Business types prefer the most popular languages because they view\nlanguages as standards. They don't want to bet the company on\nBetamax.  The thing about languages, though, is that they're not\njust standards.  If you have to move bits over a network, by all\nmeans use TCP/IP.  But a programming language isn't just a format.\nA programming language is a medium of expression.I've read that Java has just overtaken Cobol as the most popular\nlanguage.  As a standard, you couldn't wish for more.  But as a\nmedium of expression, you could do a lot better.  Of all the great\nprogrammers I can think of, I know of only one who would voluntarily\nprogram in Java.  And of all the great programmers I can think of\nwho don't work for Sun, on Java, I know of zero.Great hackers also generally insist on using open source software.\nNot just because it's better, but because it gives them more control.\nGood hackers insist on control.  This is part of what makes them\ngood hackers:  when something's broken, they need to fix it.  You\nwant them to feel this way about the software they're writing for\nyou.  You shouldn't be surprised when they feel the same way about\nthe operating system.A couple years ago a venture capitalist friend told me about a new\nstartup he was involved with.  It sounded promising.  But the next\ntime I talked to him, he said they'd decided to build their software\non Windows NT, and had just hired a very experienced NT developer\nto be their chief technical officer.  When I heard this, I thought,\nthese guys are doomed.  One, the CTO couldn't be a first rate\nhacker, because to become an eminent NT developer he would have\nhad to use NT voluntarily, multiple times, and I couldn't imagine\na great hacker doing that; and two, even if he was good, he'd have\na hard time hiring anyone good to work for him if the project had\nto be built on NT. [2]The Final FrontierAfter software, the most important tool to a hacker is probably\nhis office.  Big companies think the function of office space is to express\nrank.  But hackers use their offices for more than that: they\nuse their office as a place to think in.  And if you're a technology\ncompany, their thoughts are your product.  So making hackers work\nin a noisy, distracting environment is like having a paint factory\nwhere the air is full of soot.The cartoon strip Dilbert has a lot to say about cubicles, and with\ngood reason.  All the hackers I know despise them.  The mere prospect\nof being interrupted is enough to prevent hackers from working on\nhard problems.  If you want to get real work done in an office with\ncubicles, you have two options: work at home, or come in early or\nlate or on a weekend, when no one else is there.  Don't companies\nrealize this is a sign that something is broken?  An office\nenvironment is supposed to be something that helps\nyou work, not something you work despite.Companies like Cisco are proud that everyone there has a cubicle,\neven the CEO.  But they're not so advanced as they think; obviously\nthey still view office space as a badge of rank.  Note too that\nCisco is famous for doing very little product development in house.\nThey get new technology by buying the startups that created it-- where\npresumably the hackers did have somewhere quiet to work.One big company that understands what hackers need is Microsoft.\nI once saw a recruiting ad for Microsoft with a big picture of a\ndoor.  Work for us, the premise was, and we'll give you a place to\nwork where you can actually get work done.   And you know, Microsoft\nis remarkable among big companies in that they are able to develop\nsoftware in house.  Not well, perhaps, but well enough.If companies want hackers to be productive, they should look at\nwhat they do at home.  At home, hackers can arrange things themselves\nso they can get the most done.  And when they work at home, hackers\ndon't work in noisy, open spaces; they work in rooms with doors.  They\nwork in cosy, neighborhoody places with people around and somewhere\nto walk when they need to mull something over, instead of in glass\nboxes set in acres of parking lots.  They have a sofa they can take\na nap on when they feel tired, instead of sitting in a coma at\ntheir desk, pretending to work.  There's no crew of people with\nvacuum cleaners that roars through every evening during the prime\nhacking hours.  There are no meetings or, God forbid, corporate\nretreats or team-building exercises.  And when you look at what\nthey're doing on that computer, you'll find it reinforces what I\nsaid earlier about tools.  They may have to use Java and Windows\nat work, but at home, where they can choose for themselves, you're\nmore likely to find them using Perl and Linux.Indeed, these statistics about Cobol or Java being the most popular\nlanguage can be misleading.  What we ought to look at, if we want\nto know what tools are best, is what hackers choose when they can\nchoose freely-- that is, in projects of their own.  When you ask\nthat question, you find that open source operating systems already\nhave a dominant market share, and the number one language is probably\nPerl.InterestingAlong with good tools, hackers want interesting projects.  What\nmakes a project interesting?  Well, obviously overtly sexy\napplications like stealth planes or special effects software would\nbe interesting to work on.  But any application can be interesting\nif it poses novel technical challenges.  So it's hard to predict\nwhich problems hackers will like, because some become\ninteresting only when the people working on them discover a new\nkind of solution.  Before ITA\n(who wrote the software inside Orbitz),\nthe people working on airline fare searches probably thought it\nwas one of the most boring applications imaginable.  But ITA made\nit interesting by \nredefining the problem in a more ambitious way.I think the same thing happened at Google.  When Google was founded,\nthe conventional wisdom among the so-called portals was that search\nwas boring and unimportant.  But the guys at Google didn't think\nsearch was boring, and that's why they do it so well.This is an area where managers can make a difference.  Like a parent\nsaying to a child, I bet you can't clean up your whole room in\nten minutes, a good manager can sometimes redefine a problem as a\nmore interesting one.  Steve Jobs seems to be particularly good at\nthis, in part simply by having high standards.  There were a lot\nof small, inexpensive computers before the Mac.  He redefined the\nproblem as: make one that's beautiful.  And that probably drove\nthe developers harder than any carrot or stick could.They certainly delivered.  When the Mac first appeared, you didn't\neven have to turn it on to know it would be good; you could tell\nfrom the case.  A few weeks ago I was walking along the street in\nCambridge, and in someone's trash I saw what appeared to be a Mac\ncarrying case.  I looked inside, and there was a Mac SE.  I carried\nit home and plugged it in, and it booted.  The happy Macintosh\nface, and then the finder.  My God, it was so simple.  It was just\nlike ... Google.Hackers like to work for people with high standards.  But it's not\nenough just to be exacting.  You have to insist on the right things.\nWhich usually means that you have to be a hacker yourself.  I've\nseen occasional articles about how to manage programmers.  Really\nthere should be two articles: one about what to do if\nyou are yourself a programmer, and one about what to do if you're not.  And the \nsecond could probably be condensed into two words:  give up.The problem is not so much the day to day management.  Really good\nhackers are practically self-managing.  The problem is, if you're\nnot a hacker, you can't tell who the good hackers are.  A similar\nproblem explains why American cars are so ugly.  I call it the\ndesign paradox.  You might think that you could make your products\nbeautiful just by hiring a great designer to design them.  But if\nyou yourself don't have good taste, \nhow are you going to recognize\na good designer?  By definition you can't tell from his portfolio.\nAnd you can't go by the awards he's won or the jobs he's had,\nbecause in design, as in most fields, those tend to be driven by\nfashion and schmoozing, with actual ability a distant third.\nThere's no way around it:  you can't manage a process intended to\nproduce beautiful things without knowing what beautiful is.  American\ncars are ugly because American car companies are run by people with\nbad taste.Many people in this country think of taste as something elusive,\nor even frivolous.  It is neither.  To drive design, a manager must\nbe the most demanding user of a company's products.  And if you\nhave really good taste, you can, as Steve Jobs does, make satisfying\nyou the kind of problem that good people like to work on.Nasty Little ProblemsIt's pretty easy to say what kinds of problems are not interesting:\nthose where instead of solving a few big, clear, problems, you have\nto solve a lot of nasty little ones.  One of the worst kinds of\nprojects is writing an interface to a piece of software that's\nfull of bugs.  Another is when you have to customize\nsomething for an individual client's complex and ill-defined needs.\nTo hackers these kinds of projects are the death of a thousand\ncuts.The distinguishing feature of nasty little problems is that you\ndon't learn anything from them.   Writing a compiler is interesting\nbecause it teaches you what a compiler is.  But writing an interface\nto a buggy piece of software doesn't teach you anything, because the\nbugs are random.  [3] So it's not just fastidiousness that makes good\nhackers avoid nasty little problems.  It's more a question of\nself-preservation.  Working on nasty little problems makes you\nstupid.  Good hackers avoid it for the same reason models avoid\ncheeseburgers.Of course some problems inherently have this character.  And because\nof supply and demand, they pay especially well.  So a company that\nfound a way to get great hackers to work on tedious problems would\nbe very successful.  How would you do it?One place this happens is in startups.  At our startup we had \nRobert Morris working as a system administrator.  That's like having the\nRolling Stones play at a bar mitzvah.  You can't hire that kind of\ntalent.  But people will do any amount of drudgery for companies\nof which they're the founders.  [4]Bigger companies solve the problem by partitioning the company.\nThey get smart people to work for them by establishing a separate\nR&D department where employees don't have to work directly on\ncustomers' nasty little problems. [5] In this model, the research\ndepartment functions like a mine. They produce new ideas; maybe\nthe rest of the company will be able to use them.You may not have to go to this extreme.  \nBottom-up programming\nsuggests another way to partition the company: have the smart people\nwork as toolmakers.  If your company makes software to do x, have\none group that builds tools for writing software of that type, and\nanother that uses these tools to write the applications.  This way\nyou might be able to get smart people to write 99% of your code,\nbut still keep them almost as insulated from users as they would\nbe in a traditional research department.  The toolmakers would have\nusers, but they'd only be the company's own developers.  [6]If Microsoft used this approach, their software wouldn't be so full\nof security holes, because the less smart people writing the actual\napplications wouldn't be doing low-level stuff like allocating\nmemory.  Instead of writing Word directly in C, they'd be plugging\ntogether big Lego blocks of Word-language.  (Duplo, I believe, is\nthe technical term.)ClumpingAlong with interesting problems, what good hackers like is other\ngood hackers.  Great hackers tend to clump together-- sometimes\nspectacularly so, as at Xerox Parc.   So you won't attract good\nhackers in linear proportion to how good an environment you create\nfor them.  The tendency to clump means it's more like the square\nof the environment.  So it's winner take all.  At any given time,\nthere are only about ten or twenty places where hackers most want to\nwork, and if you aren't one of them, you won't just have fewer\ngreat hackers, you'll have zero.Having great hackers is not, by itself, enough to make a company\nsuccessful.  It works well for Google and ITA, which are two of\nthe hot spots right now, but it didn't help Thinking Machines or\nXerox.  Sun had a good run for a while, but their business model\nis a down elevator.\nThe best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.\n  In that situation, even the best hackers can't\nsave you.I think, though, that all other things being equal, a company that\ncan attract great hackers will have a huge advantage.  There are\npeople who would disagree with this.  When we were making the rounds\nof venture capital firms in the 1990s, several told us that software\ncompanies didn't win by writing great software, but through brand,\nand dominating channels, and doing the right deals.They really seemed to believe this, and I think I know why.  I\nthink what a lot of VCs are looking for, at least unconsciously,\nis the next Microsoft.  And of course if Microsoft is your model,\nyou shouldn't be looking for companies that hope to win by writing\ngreat software.  But VCs are mistaken to look for the next Microsoft,\nbecause no startup can be the next Microsoft unless some other\ncompany is prepared to bend over at just the right moment and be\nthe next IBM.It's a mistake to use Microsoft as a model, because their whole\nculture derives from that one lucky break.  Microsoft is a bad data\npoint.  If you throw them out, you find that good products do tend\nto win in the market.  What VCs should be looking for is the next\nApple, or the next Google.I think Bill Gates knows this.  What worries him about Google is\nnot the power of their brand, but the fact that they have\nbetter hackers. [7]\nRecognitionSo who are the great hackers?  How do you know when you meet one?\nThat turns out to be very hard.  Even hackers can't tell.  I'm\npretty sure now that my friend Trevor Blackwell is a great hacker.\nYou may have read on Slashdot how he made his \nown Segway.  The\nremarkable thing about this project was that he wrote all the\nsoftware in one day (in Python, incidentally).For Trevor, that's\npar for the course.  But when I first met him, I thought he was a\ncomplete idiot.  He was standing in Robert Morris's office babbling\nat him about something or other, and I remember standing behind\nhim making frantic gestures at Robert to shoo this nut out of his\noffice so we could go to lunch.  Robert says he misjudged Trevor\nat first too.  Apparently when Robert first met him, Trevor had\njust begun a new scheme that involved writing down everything about\nevery aspect of his life on a stack of index cards, which he carried\nwith him everywhere.  He'd also just arrived from Canada, and had\na strong Canadian accent and a mullet.The problem is compounded by the fact that hackers, despite their\nreputation for social obliviousness, sometimes put a good deal of\neffort into seeming smart.  When I was in grad school I used to\nhang around the MIT AI Lab occasionally. It was kind of intimidating\nat first.  Everyone there spoke so fast.  But after a while I\nlearned the trick of speaking fast.  You don't have to think any\nfaster; just use twice as many words to say everything.  With this amount of noise in the signal, it's hard to tell good\nhackers when you meet them.  I can't tell, even now.  You also\ncan't tell from their resumes.  It seems like the only way to judge\na hacker is to work with him on something.And this is the reason that high-tech areas \nonly happen around universities.  The active ingredient\nhere is not so much the professors as the students.  Startups grow up\naround universities because universities bring together promising young\npeople and make them work on the same projects.  The\nsmart ones learn who the other smart ones are, and together\nthey cook up new projects of their own.Because you can't tell a great hacker except by working with him,\nhackers themselves can't tell how good they are.  This is true to\na degree in most fields.  I've found that people who\nare great at something are not so much convinced of their own\ngreatness as mystified at why everyone else seems so incompetent.\nBut it's particularly hard for hackers to know how good they are,\nbecause it's hard to compare their work.  This is easier in most\nother fields.  In the hundred meters, you know in 10 seconds who's\nfastest.  Even in math there seems to be a general consensus about\nwhich problems are hard to solve, and what constitutes a good\nsolution.  But hacking is like writing.  Who can say which of two\nnovels is better?  Certainly not the authors.With hackers, at least, other hackers can tell.  That's because,\nunlike novelists, hackers collaborate on projects.  When you get\nto hit a few difficult problems over the net at someone, you learn\npretty quickly how hard they hit them back.  But hackers can't\nwatch themselves at work.  So if you ask a great hacker how good\nhe is, he's almost certain to reply, I don't know.  He's not just\nbeing modest.  He really doesn't know.And none of us know, except about people we've actually worked\nwith.  Which puts us in a weird situation: we don't know who our\nheroes should be.  The hackers who become famous tend to become\nfamous by random accidents of PR.  Occasionally I need to give an\nexample of a great hacker, and I never know who to use.  The first\nnames that come to mind always tend to be people I know personally,\nbut it seems lame to use them.  So, I think, maybe I should say\nRichard Stallman, or Linus Torvalds, or Alan Kay, or someone famous\nlike that.  But I have no idea if these guys are great hackers.\nI've never worked with them on anything.If there is a Michael Jordan of hacking, no one knows, including\nhim.CultivationFinally, the question the hackers have all been wondering about:\nhow do you become a great hacker?  I don't know if it's possible\nto make yourself into one.  But it's certainly possible to do things\nthat make you stupid, and if you can make yourself stupid, you\ncan probably make yourself smart too.The key to being a good hacker may be to work on what you like.\nWhen I think about the great hackers I know, one thing they have\nin common is the extreme \ndifficulty of making them work \non anything they\ndon't want to.  I don't know if this is cause or effect; it may be\nboth.To do something well you have to love it.  \nSo to the extent you\ncan preserve hacking as something you love, you're likely to do it\nwell.  Try to keep the sense of wonder you had about programming at\nage 14.  If you're worried that your current job is rotting your\nbrain, it probably is.The best hackers tend to be smart, of course, but that's true in\na lot of fields.  Is there some quality that's unique to hackers?\nI asked some friends, and the number one thing they mentioned was\ncuriosity.  \nI'd always supposed that all smart people were curious--\nthat curiosity was simply the first derivative of knowledge.  But\napparently hackers are particularly curious, especially about how\nthings work.  That makes sense, because programs are in effect\ngiant descriptions of how things work.Several friends mentioned hackers' ability to concentrate-- their\nability, as one put it, to \"tune out everything outside their own\nheads.''  I've certainly noticed this.  And I've heard several \nhackers say that after drinking even half a beer they can't program at\nall.   So maybe hacking does require some special ability to focus.\nPerhaps great hackers can load a large amount of context into their\nhead, so that when they look at a line of code, they see not just\nthat line but the whole program around it.  John McPhee\nwrote that Bill Bradley's success as a basketball player was due\npartly to his extraordinary peripheral vision.  \"Perfect'' eyesight\nmeans about 47 degrees of vertical peripheral vision.  Bill Bradley\nhad 70; he could see the basket when he was looking at the floor.\nMaybe great hackers have some similar inborn ability.  (I cheat by\nusing a very dense language, \nwhich shrinks the court.)This could explain the disconnect over cubicles.  Maybe the people\nin charge of facilities, not having any concentration to shatter,\nhave no idea that working in a cubicle feels to a hacker like having\none's brain in a blender.  (Whereas Bill, if the rumors of autism\nare true, knows all too well.)One difference I've noticed between great hackers and smart people\nin general is that hackers are more \npolitically incorrect.  To the\nextent there is a secret handshake among good hackers, it's when they\nknow one another well enough to express opinions that would get\nthem stoned to death by the general public.  And I can see why\npolitical incorrectness would be a useful quality in programming.\nPrograms are very complex and, at least in the hands of good\nprogrammers, very fluid.  In such situations it's helpful to have\na habit of questioning assumptions.Can you cultivate these qualities?  I don't know.  But you can at\nleast not repress them.  So here is my best shot at a recipe.  If\nit is possible to make yourself into a great hacker, the way to do\nit may be to make the following deal with yourself: you never have\nto work on boring projects (unless your family will starve otherwise),\nand in return, you'll never allow yourself to do a half-assed job.\nAll the great hackers I know seem to have made that deal, though\nperhaps none of them had any choice in the matter.Notes\n[1] In fairness, I have to say that IBM makes decent hardware.  I\nwrote this on an IBM laptop.[2] They did turn out to be doomed.  They shut down a few months\nlater.[3] I think this is what people mean when they talk\nabout the \"meaning of life.\"  On the face of it, this seems an \nodd idea.  Life isn't an expression; how could it have meaning?\nBut it can have a quality that feels a lot like meaning.  In a project\nlike a compiler, you have to solve a lot of problems, but the problems\nall fall into a pattern, as in a signal.  Whereas when the problems\nyou have to solve are random, they seem like noise.\n[4] Einstein at one point worked designing refrigerators. (He had equity.)[5] It's hard to say exactly what constitutes research in the\ncomputer world, but as a first approximation, it's software that\ndoesn't have users.I don't think it's publication that makes the best hackers want to work\nin research departments.  I think it's mainly not having to have a\nthree hour meeting with a product manager about problems integrating\nthe Korean version of Word 13.27 with the talking paperclip.[6] Something similar has been happening for a long time in the\nconstruction industry. When you had a house built a couple hundred\nyears ago, the local builders built everything in it.  But increasingly\nwhat builders do is assemble components designed and manufactured\nby someone else.  This has, like the arrival of desktop publishing,\ngiven people the freedom to experiment in disastrous ways, but it\nis certainly more efficient.[7] Google is much more dangerous to Microsoft than Netscape was.\nProbably more dangerous than any other company has ever been.  Not\nleast because they're determined to fight.  On their job listing\npage, they say that one of their \"core values'' is \"Don't be evil.''\nFrom a company selling soybean oil or mining equipment, such a\nstatement would merely be eccentric.  But I think all of us in the\ncomputer world recognize who that is a declaration of war on.Thanks to Jessica Livingston, Robert Morris, and Sarah Harlin\nfor reading earlier versions of this talk.January 2015Corporate Development, aka corp dev, is the group within companies\nthat buys other companies. If you're talking to someone from corp\ndev, that's why, whether you realize it yet or not.It's usually a mistake to talk to corp dev unless (a) you want to\nsell your company right now and (b) you're sufficiently likely to\nget an offer at an acceptable price.  In practice that means startups\nshould only talk to corp dev when they're either doing really well\nor really badly.  If you're doing really badly, meaning the company\nis about to die, you may as well talk to them, because you have\nnothing to lose. And if you're doing really well, you can safely\ntalk to them, because you both know the price will have to be high,\nand if they show the slightest sign of wasting your time, you'll\nbe confident enough to tell them to get lost.The danger is to companies in the middle.  Particularly to young\ncompanies that are growing fast, but haven't been doing it for long\nenough to have grown big yet.  It's usually a mistake for a promising\ncompany less than a year old even to talk to corp dev.But it's a mistake founders constantly make.  When someone from\ncorp dev wants to meet, the founders tell themselves they should\nat least find out what they want.  Besides, they don't want to\noffend Big Company by refusing to meet.Well, I'll tell you what they want.  They want to talk about buying\nyou.  That's what the title \"corp dev\" means.   So before agreeing\nto meet with someone from corp dev, ask yourselves, \"Do we want to\nsell the company right now?\"  And if the answer is no, tell them\n\"Sorry, but we're focusing on growing the company.\"  They won't be\noffended.  And certainly the founders of Big Company won't be\noffended. If anything they'll think more highly of you.  You'll\nremind them of themselves.  They didn't sell either; that's why\nthey're in a position now to buy other companies.\n[1]Most founders who get contacted by corp dev already know what it\nmeans.  And yet even when they know what corp dev does and know\nthey don't want to sell, they take the meeting.  Why do they do it?\nThe same mix of denial and wishful thinking that underlies most\nmistakes founders make. It's flattering to talk to someone who wants\nto buy you.  And who knows, maybe their offer will be surprisingly\nhigh.  You should at least see what it is, right?No.  If they were going to send you an offer immediately by email,\nsure, you might as well open it.  But that is not how conversations\nwith corp dev work.  If you get an offer at all, it will be at the\nend of a long and unbelievably distracting process.  And if the\noffer is surprising, it will be surprisingly low.Distractions are the thing you can least afford in a startup.  And\nconversations with corp dev are the worst sort of distraction,\nbecause as well as consuming your attention they undermine your\nmorale.  One of the tricks to surviving a grueling process is not\nto stop and think how tired you are.  Instead you get into a sort\nof flow. \n[2]\nImagine what it would do to you if at mile 20 of a\nmarathon, someone ran up beside you and said \"You must feel really\ntired.  Would you like to stop and take a rest?\"  Conversations\nwith corp dev are like that but worse, because the suggestion of\nstopping gets combined in your mind with the imaginary high price\nyou think they'll offer.And then you're really in trouble.  If they can, corp dev people\nlike to turn the tables on you. They like to get you to the point\nwhere you're trying to convince them to buy instead of them trying\nto convince you to sell.  And surprisingly often they succeed.This is a very slippery slope, greased with some of the most powerful\nforces that can work on founders' minds, and attended by an experienced\nprofessional whose full time job is to push you down it.Their tactics in pushing you down that slope are usually fairly\nbrutal. Corp dev people's whole job is to buy companies, and they\ndon't even get to choose which.  The only way their performance is\nmeasured is by how cheaply they can buy you, and the more ambitious\nones will stop at nothing to achieve that. For example, they'll\nalmost always start with a lowball offer, just to see if you'll\ntake it. Even if you don't, a low initial offer will demoralize you\nand make you easier to manipulate.And that is the most innocent of their tactics. Just wait till\nyou've agreed on a price and think you have a done deal, and then\nthey come back and say their boss has vetoed the deal and won't do\nit for more than half the agreed upon price. Happens all the time.\nIf you think investors can behave badly, it's nothing compared to\nwhat corp dev people can do.  Even corp dev people at companies\nthat are otherwise benevolent.I remember once complaining to a\nfriend at Google about some nasty trick their corp dev people had\npulled on a YC startup.\"What happened to Don't be Evil?\" I asked.\"I don't think corp dev got the memo,\" he replied.The tactics you encounter in M&A conversations can be like nothing\nyou've experienced in the otherwise comparatively \nupstanding world\nof Silicon Valley.  It's as if a chunk of genetic material from the\nold-fashioned robber baron business world got incorporated into the\nstartup world.\n[3]The simplest way to protect yourself is to use the trick that John\nD. Rockefeller, whose grandfather was an alcoholic, used to protect\nhimself from becoming one.  He once told a Sunday school class\n\n  Boys, do you know why I never became a drunkard?  Because I never\n  took the first drink.\n\nDo you want to sell your company right now?  Not eventually, right\nnow.  If not, just don't take the first meeting.  They won't be\noffended.  And you in turn will be guaranteed to be spared one of\nthe worst experiences that can happen to a startup.If you do want to sell, there's another set of \ntechniques\n for doing\nthat.  But the biggest mistake founders make in dealing with corp\ndev is not doing a bad job of talking to them when they're ready\nto, but talking to them before they are.  So if you remember only\nthe title of this essay, you already know most of what you need to\nknow about M&A in the first year.Notes[1]\nI'm not saying you should never sell.  I'm saying you should\nbe clear in your own mind about whether you want to sell or not,\nand not be led by manipulation or wishful thinking into trying to\nsell earlier than you otherwise would have.[2]\nIn a startup, as in most competitive sports, the task at hand\nalmost does this for you; you're too busy to feel tired.  But when\nyou lose that protection, e.g. at the final whistle, the fatigue\nhits you like a wave.  To talk to corp dev is to let yourself feel\nit mid-game.[3]\nTo be fair, the apparent misdeeds of corp dev people are magnified\nby the fact that they function as the face of a large organization\nthat often doesn't know its own mind.  Acquirers can be surprisingly\nindecisive about acquisitions, and their flakiness is indistinguishable\nfrom dishonesty by the time it filters down to you.Thanks to Marc Andreessen, Jessica Livingston, Geoff\nRalston, and Qasar Younis for reading drafts of this.December 2014I've read Villehardouin's chronicle of the Fourth Crusade at least\ntwo times, maybe three.  And yet if I had to write down everything\nI remember from it, I doubt it would amount to much more than a\npage.  Multiply this times several hundred, and I get an uneasy\nfeeling when I look at my bookshelves. What use is it to read all\nthese books if I remember so little from them?A few months ago, as I was reading Constance Reid's excellent\nbiography of Hilbert, I figured out if not the answer to this\nquestion, at least something that made me feel better about it.\nShe writes:\n\n  Hilbert had no patience with mathematical lectures which filled\n  the students with facts but did not teach them how to frame a\n  problem and solve it. He often used to tell them that \"a perfect\n  formulation of a problem is already half its solution.\"\n\nThat has always seemed to me an important point, and I was even\nmore convinced of it after hearing it confirmed by Hilbert.But how had I come to believe in this idea in the first place?  A\ncombination of my own experience and other things I'd read.  None\nof which I could at that moment remember!  And eventually I'd forget\nthat Hilbert had confirmed it too.  But my increased belief in the\nimportance of this idea would remain something I'd learned from\nthis book, even after I'd forgotten I'd learned it.Reading and experience train your model of the world.  And even if\nyou forget the experience or what you read, its effect on your model\nof the world persists.  Your mind is like a compiled program you've\nlost the source of.  It works, but you don't know why.The place to look for what I learned from Villehardouin's chronicle\nis not what I remember from it, but my mental models of the crusades,\nVenice, medieval culture, siege warfare, and so on.  Which doesn't\nmean I couldn't have read more attentively, but at least the harvest\nof reading is not so miserably small as it might seem.This is one of those things that seem obvious in retrospect.  But\nit was a surprise to me and presumably would be to anyone else who\nfelt uneasy about (apparently) forgetting so much they'd read.Realizing it does more than make you feel a little better about\nforgetting, though.  There are specific implications.For example, reading and experience are usually \"compiled\" at the\ntime they happen, using the state of your brain at that time.  The\nsame book would get compiled differently at different points in\nyour life.  Which means it is very much worth reading important\nbooks multiple times.  I always used to feel some misgivings about\nrereading books.  I unconsciously lumped reading together with work\nlike carpentry, where having to do something again is a sign you\ndid it wrong the first time.  Whereas now the phrase \"already read\"\nseems almost ill-formed.Intriguingly, this implication isn't limited to books.  Technology\nwill increasingly make it possible to relive our experiences.  When\npeople do that today it's usually to enjoy them again (e.g. when\nlooking at pictures of a trip) or to find the origin of some bug in\ntheir compiled code (e.g. when Stephen Fry succeeded in remembering\nthe childhood trauma that prevented him from singing).  But as\ntechnologies for recording and playing back your life improve, it\nmay become common for people to relive experiences without any goal\nin mind, simply to learn from them again as one might when rereading\na book.Eventually we may be able not just to play back experiences but\nalso to index and even edit them. So although not knowing how you\nknow things may seem part of being human, it may not be.\nThanks to Sam Altman, Jessica Livingston, and Robert Morris for reading \ndrafts of this.\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nOctober 2010\n\n(I wrote this for Forbes, who asked me to write something\nabout the qualities we look for in founders.  In print they had to cut\nthe last item because they didn't have room.)1. DeterminationThis has turned out to be the most important quality in startup\nfounders.  We thought when we started Y Combinator that the most\nimportant quality would be intelligence.  That's the myth in the\nValley. And certainly you don't want founders to be stupid.  But\nas long as you're over a certain threshold of intelligence, what\nmatters most is determination.  You're going to hit a lot of\nobstacles.  You can't be the sort of person who gets demoralized\neasily.Bill Clerico and Rich Aberman of WePay \nare a good example.  They're\ndoing a finance startup, which means endless negotiations with big,\nbureaucratic companies.  When you're starting a startup that depends\non deals with big companies to exist, it often feels like they're\ntrying to ignore you out of existence.  But when Bill Clerico starts\ncalling you, you may as well do what he asks, because he is not\ngoing away.\n2. FlexibilityYou do not however want the sort of determination implied by phrases\nlike \"don't give up on your dreams.\"  The world of startups is so\nunpredictable that you need to be able to modify your dreams on the\nfly.  The best metaphor I've found for the combination of determination\nand flexibility you need is a running back.  \nHe's determined to get\ndownfield, but at any given moment he may need to go sideways or\neven backwards to get there.The current record holder for flexibility may be Daniel Gross of\nGreplin.  He applied to YC with \nsome bad ecommerce idea.  We told\nhim we'd fund him if he did something else.  He thought for a second,\nand said ok.  He then went through two more ideas before settling\non Greplin.  He'd only been working on it for a couple days when\nhe presented to investors at Demo Day, but he got a lot of interest.\nHe always seems to land on his feet.\n3. ImaginationIntelligence does matter a lot of course.  It seems like the type\nthat matters most is imagination.  It's not so important to be able\nto solve predefined problems quickly as to be able to come up with\nsurprising new ideas.  In the startup world, most good ideas \nseem\nbad initially.  If they were obviously good, someone would already\nbe doing them.  So you need the kind of intelligence that produces\nideas with just the right level of craziness.Airbnb is that kind of idea.  \nIn fact, when we funded Airbnb, we\nthought it was too crazy.  We couldn't believe large numbers of\npeople would want to stay in other people's places.  We funded them\nbecause we liked the founders so much.  As soon as we heard they'd\nbeen supporting themselves by selling Obama and McCain branded\nbreakfast cereal, they were in.  And it turned out the idea was on\nthe right side of crazy after all.\n4. NaughtinessThough the most successful founders are usually good people, they\ntend to have a piratical gleam in their eye.  They're not Goody\nTwo-Shoes type good.  Morally, they care about getting the big\nquestions right, but not about observing proprieties.  That's why\nI'd use the word naughty rather than evil.  They delight in \nbreaking\nrules, but not rules that matter.  This quality may be redundant\nthough; it may be implied by imagination.Sam Altman of Loopt \nis one of the most successful alumni, so we\nasked him what question we could put on the Y Combinator application\nthat would help us discover more people like him.  He said to ask\nabout a time when they'd hacked something to their advantage\u2014hacked in the sense of beating the system, not breaking into\ncomputers.  It has become one of the questions we pay most attention\nto when judging applications.\n5. FriendshipEmpirically it seems to be hard to start a startup with just \none\nfounder.  Most of the big successes have two or three.  And the\nrelationship between the founders has to be strong.  They must\ngenuinely like one another, and work well together.  Startups do\nto the relationship between the founders what a dog does to a sock:\nif it can be pulled apart, it will be.Emmett Shear and Justin Kan of Justin.tv \nare a good example of close\nfriends who work well together.  They've known each other since\nsecond grade.  They can practically read one another's minds.  I'm\nsure they argue, like all founders, but I have never once sensed\nany unresolved tension between them.Thanks to Jessica Livingston and Chris Steiner for reading drafts of this.January 2012A few hours before the Yahoo acquisition was announced in June 1998\nI took a snapshot of Viaweb's\nsite.  I thought it might be interesting to look at one day.The first thing one notices is is how tiny the pages are.  Screens\nwere a lot smaller in 1998.  If I remember correctly, our frontpage\nused to just fit in the size window people typically used then.Browsers then (IE 6 was still 3 years in the future) had few fonts\nand they weren't antialiased.  If you wanted to make pages that\nlooked good, you had to render display text as images.You may notice a certain similarity between the Viaweb and Y Combinator logos.  We did that\nas an inside joke when we started YC.  Considering how basic a red\ncircle is, it seemed surprising to me when we started Viaweb how\nfew other companies used one as their logo.  A bit later I realized\nwhy.On the Company\npage you'll notice a mysterious individual called John McArtyem.\nRobert Morris (aka Rtm) was so publicity averse after the \nWorm that he\ndidn't want his name on the site.  I managed to get him to agree\nto a compromise: we could use his bio but not his name.  He has\nsince relaxed a bit\non that point.Trevor graduated at about the same time the acquisition closed, so in the\ncourse of 4 days he went from impecunious grad student to millionaire\nPhD.  The culmination of my career as a writer of press releases\nwas one celebrating\nhis graduation, illustrated with a drawing I did of him during\na meeting.(Trevor also appears as Trevino\nBagwell in our directory of web designers merchants could hire\nto build stores for them.  We inserted him as a ringer in case some\ncompetitor tried to spam our web designers.   We assumed his logo\nwould deter any actual customers, but it did not.)Back in the 90s, to get users you had to get mentioned in magazines\nand newspapers.  There were not the same ways to get found online\nthat there are today.  So we used to pay a PR\nfirm $16,000 a month to get us mentioned in the press.  Fortunately\nreporters liked\nus.In our advice about\ngetting traffic from search engines (I don't think the term SEO\nhad been coined yet), we say there are only 7 that matter: Yahoo,\nAltaVista, Excite, WebCrawler, InfoSeek, Lycos, and HotBot.  Notice\nanything missing?  Google was incorporated that September.We supported online transactions via a company called \nCybercash,\nsince if we lacked that feature we'd have gotten beaten up in product\ncomparisons.  But Cybercash was so bad and most stores' order volumes\nwere so low that it was better if merchants processed orders like phone orders.  We had a page in our site trying to talk merchants\nout of doing real time authorizations.The whole site was organized like a funnel, directing people to the\ntest drive.\nIt was a novel thing to be able to try out software online.  We put\ncgi-bin in our dynamic urls to fool competitors about how our\nsoftware worked.We had some well\nknown users.  Needless to say, Frederick's of Hollywood got the\nmost traffic.  We charged a flat fee of $300/month for big stores,\nso it was a little alarming to have users who got lots of traffic.\nI once calculated how much Frederick's was costing us in bandwidth,\nand it was about $300/month.Since we hosted all the stores, which together were getting just\nover 10 million page views per month in June 1998, we consumed what\nat the time seemed a lot of bandwidth.  We had 2 T1s (3 Mb/sec)\ncoming into our offices.  In those days there was no AWS.  Even\ncolocating servers seemed too risky, considering how often things\nwent wrong with them.  So we had our servers in our offices.  Or\nmore precisely, in Trevor's office.  In return for the unique\nprivilege of sharing his office with no other humans, he had to\nshare it with 6 shrieking tower servers.  His office was nicknamed\nthe Hot Tub on account of the heat they generated.  Most days his\nstack of window air conditioners could keep up.For describing pages, we had a template language called RTML, which\nsupposedly stood for something, but which in fact I named after\nRtm.  RTML was Common Lisp augmented by some macros and libraries,\nand concealed under a structure editor that made it look like it\nhad syntax.Since we did continuous releases, our software didn't actually have\nversions.  But in those days the trade press expected versions, so\nwe made them up.  If we wanted to get lots of attention, we made\nthe version number an\ninteger.  That \"version 4.0\" icon was generated by our own\nbutton generator, incidentally.  The whole Viaweb site was made\nwith our software, even though it wasn't an online store, because\nwe wanted to experience what our users did.At the end of 1997, we released a general purpose shopping search\nengine called Shopfind.  It\nwas pretty advanced for the time.  It had a programmable crawler\nthat could crawl most of the different stores online and pick out\nthe products.October 2015When I talk to a startup that's been operating for more than 8 or\n9 months, the first thing I want to know is almost always the same.\nAssuming their expenses remain constant and their revenue growth\nis what it has been over the last several months, do they make it to\nprofitability on the money they have left?  Or to put it more\ndramatically, by default do they live or die?The startling thing is how often the founders themselves don't know.\nHalf the founders I talk to don't know whether they're default alive\nor default dead.If you're among that number, Trevor Blackwell has made a handy\ncalculator you can use to find out.The reason I want to know first whether a startup is default alive\nor default dead is that the rest of the conversation depends on the\nanswer.  If the company is default alive, we can talk about ambitious\nnew things they could do.  If it's default dead, we probably need\nto talk about how to save it.  We know the current trajectory ends\nbadly.  How can they get off that trajectory?Why do so few founders know whether they're default alive or default\ndead?  Mainly, I think, because they're not used to asking that.\nIt's not a question that makes sense to ask early on, any more than\nit makes sense to ask a 3 year old how he plans to support\nhimself.  But as the company grows older, the question switches from\nmeaningless to critical.  That kind of switch often takes people\nby surprise.I propose the following solution: instead of starting to ask too\nlate whether you're default alive or default dead, start asking too\nearly.  It's hard to say precisely when the question switches\npolarity.  But it's probably not that dangerous to start worrying\ntoo early that you're default dead, whereas it's very dangerous to\nstart worrying too late.The reason is a phenomenon I wrote about earlier: the\nfatal pinch.\nThe fatal pinch is default dead + slow growth + not enough\ntime to fix it.  And the way founders end up in it is by not realizing\nthat's where they're headed.There is another reason founders don't ask themselves whether they're\ndefault alive or default dead: they assume it will be easy to raise\nmore money.  But that assumption is often false, and worse still, the\nmore you depend on it, the falser it becomes.Maybe it will help to separate facts from hopes. Instead of thinking\nof the future with vague optimism, explicitly separate the components.\nSay \"We're default dead, but we're counting on investors to save\nus.\" Maybe as you say that, it will set off the same alarms in your\nhead that it does in mine.  And if you set off the alarms sufficiently\nearly, you may be able to avoid the fatal pinch.It would be safe to be default dead if you could count on investors\nsaving you.  As a rule their interest is a function of\ngrowth.  If you have steep revenue growth, say over 5x a year, you\ncan start to count on investors being interested even if you're not\nprofitable.\n[1]\nBut investors are so fickle that you can never\ndo more than start to count on them.  Sometimes something about your\nbusiness will spook investors even if your growth is great.  So no\nmatter how good your growth is, you can never safely treat fundraising\nas more than a plan A. You should always have a plan B as well: you\nshould know (as in write down) precisely what you'll need to do to\nsurvive if you can't raise more money, and precisely when you'll \nhave to switch to plan B if plan A isn't working.In any case, growing fast versus operating cheaply is far from the\nsharp dichotomy many founders assume it to be.  In practice there\nis surprisingly little connection between how much a startup spends\nand how fast it grows.  When a startup grows fast, it's usually\nbecause the product hits a nerve, in the sense of hitting some big\nneed straight on.  When a startup spends a lot, it's usually because\nthe product is expensive to develop or sell, or simply because\nthey're wasteful.If you're paying attention, you'll be asking at this point not just\nhow to avoid the fatal pinch, but how to avoid being default dead.\nThat one is easy: don't hire too fast.  Hiring too fast is by far\nthe biggest killer of startups that raise money.\n[2]Founders tell themselves they need to hire in order to grow.  But\nmost err on the side of overestimating this need rather than\nunderestimating it.  Why?  Partly because there's so much work to\ndo.  Naive founders think that if they can just hire enough\npeople, it will all get done.  Partly because successful startups have\nlots of employees, so it seems like that's what one does in order\nto be successful.  In fact the large staffs of successful startups\nare probably more the effect of growth than the cause.  And\npartly because when founders have slow growth they don't want to\nface what is usually the real reason: the product is not appealing\nenough.Plus founders who've just raised money are often encouraged to\noverhire by the VCs who funded them.  Kill-or-cure strategies are\noptimal for VCs because they're protected by the portfolio effect.\nVCs want to blow you up, in one sense of the phrase or the other.\nBut as a founder your incentives are different.  You want above all\nto survive.\n[3]Here's a common way startups die.  They make something moderately\nappealing and have decent initial growth. They raise their first\nround fairly easily, because the founders seem smart and the idea\nsounds plausible. But because the product is only moderately\nappealing, growth is ok but not great.  The founders convince\nthemselves that hiring a bunch of people is the way to boost growth.\nTheir investors agree.  But (because the product is only moderately\nappealing) the growth never comes.  Now they're rapidly running out\nof runway.  They hope further investment will save them. But because\nthey have high expenses and slow growth, they're now unappealing\nto investors. They're unable to raise more, and the company dies.What the company should have done is address the fundamental problem:\nthat the product is only moderately appealing.  Hiring people is\nrarely the way to fix that.  More often than not it makes it harder.\nAt this early stage, the product needs to evolve more than to be\n\"built out,\" and that's usually easier with fewer people.\n[4]Asking whether you're default alive or default dead may save you\nfrom this.  Maybe the alarm bells it sets off will counteract the\nforces that push you to overhire.  Instead you'll be compelled to\nseek growth in other ways. For example, by doing\nthings that don't scale, or by redesigning the product in the\nway only founders can.\nAnd for many if not most startups, these paths to growth will be\nthe ones that actually work.Airbnb waited 4 months after raising money at the end of Y\u00a0Combinator\nbefore they hired their first employee.  In the meantime the founders\nwere terribly overworked.  But they were overworked evolving Airbnb\ninto the astonishingly successful organism it is now.Notes[1]\nSteep usage growth will also interest investors.  Revenue\nwill ultimately be a constant multiple of usage, so x% usage growth\npredicts x% revenue growth.  But in practice investors discount\nmerely predicted revenue, so if you're measuring usage you need a\nhigher growth rate to impress investors.[2]\nStartups that don't raise money are saved from hiring too\nfast because they can't afford to. But that doesn't mean you should\navoid raising money in order to avoid this problem, any more than\nthat total abstinence is the only way to avoid becoming an alcoholic.[3]\nI would not be surprised if VCs' tendency to push founders\nto overhire is not even in their own interest.  They don't know how\nmany of the companies that get killed by overspending might have\ndone well if they'd survived.  My guess is a significant number.[4]\nAfter reading a draft, Sam Altman wrote:\"I think you should make the hiring point more strongly.  I think\nit's roughly correct to say that YC's most successful companies\nhave never been the fastest to hire, and one of the marks of a great\nfounder is being able to resist this urge.\"Paul Buchheit adds:\"A related problem that I see a lot is premature scaling\u2014founders\ntake a small business that isn't really working (bad unit economics,\ntypically) and then scale it up because they want impressive growth\nnumbers. This is similar to over-hiring in that it makes the business\nmuch harder to fix once it's big, plus they are bleeding cash really\nfast.\"\nThanks to Sam Altman, Paul Buchheit, Joe Gebbia, Jessica Livingston,\nand Geoff Ralston for reading drafts of this.\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nOctober 2010After barely changing at all for decades, the startup funding\nbusiness is now in what could, at least by comparison, be called\nturmoil.  At Y Combinator we've seen dramatic changes in the funding\nenvironment for startups.  Fortunately one of them is much higher\nvaluations.The trends we've been seeing are probably not YC-specific.  I wish\nI could say they were, but the main cause is probably just that we\nsee trends first\u2014partly because the startups we fund are very\nplugged into the Valley and are quick to take advantage of anything\nnew, and partly because we fund so many that we have enough data\npoints to see patterns clearly.What we're seeing now, everyone's probably going to be seeing in\nthe next couple years.  So I'm going to explain what we're seeing,\nand what that will mean for you if you try to raise money.Super-AngelsLet me start by describing what the world of startup funding used\nto look like.  There used to be two sharply differentiated types\nof investors: angels and venture capitalists.  Angels are individual\nrich people who invest small amounts of their own money, while VCs\nare employees of funds that invest large amounts of other people's.For decades there were just those two types of investors, but now\na third type has appeared halfway between them: the so-called\nsuper-angels. \n[1]\n  And VCs have been provoked by their arrival\ninto making a lot of angel-style investments themselves.  So the\npreviously sharp line between angels and VCs has become hopelessly\nblurred.There used to be a no man's land between angels and VCs.  Angels\nwould invest $20k to $50k apiece, and VCs usually a million or more.\nSo an angel round meant a collection of angel investments that\ncombined to maybe $200k, and a VC round meant a series A round in\nwhich a single VC fund (or occasionally two) invested $1-5 million.The no man's land between angels and VCs was a very inconvenient\none for startups, because it coincided with the amount many wanted\nto raise.  Most startups coming out of Demo Day wanted to raise\naround $400k.  But it was a pain to stitch together that much out\nof angel investments, and most VCs weren't interested in investments\nso small.  That's the fundamental reason the super-angels have\nappeared.  They're responding to the market.The arrival of a new type of investor is big news for startups,\nbecause there used to be only two and they rarely competed with one\nanother.  Super-angels compete with both angels and VCs.  That's\ngoing to change the rules about how to raise money.  I don't know\nyet what the new rules will be, but it looks like most of the changes\nwill be for the better.A super-angel has some of the qualities of an angel, and some of\nthe qualities of a VC.  They're usually individuals, like angels.\nIn fact many of the current super-angels were initially angels of\nthe classic type.  But like VCs, they invest other people's money.\nThis allows them to invest larger amounts than angels:  a typical\nsuper-angel investment is currently about $100k.  They make investment\ndecisions quickly, like angels.  And they make a lot more investments\nper partner than VCs\u2014up to 10 times as many.The fact that super-angels invest other people's money makes them\ndoubly alarming to VCs. They don't just compete for startups; they\nalso compete for investors.  What super-angels really are is a new\nform of fast-moving, lightweight VC fund.   And those of us in the\ntechnology world know what usually happens when something comes\nalong that can be described in terms like that.  Usually it's the\nreplacement.Will it be?  As of now, few of the startups that take money from\nsuper-angels are ruling out taking VC money.  They're just postponing\nit.  But that's still a problem for VCs.  Some of the startups that\npostpone raising VC money may do so well on the angel money they\nraise that they never bother to raise more.  And those who do raise\nVC rounds will be able to get higher valuations when they do.  If\nthe best startups get 10x higher valuations when they raise series\nA rounds, that would cut VCs' returns from winners at least tenfold.\n[2]So I think VC funds are seriously threatened by the super-angels.\nBut one thing that may save them to some extent is the uneven\ndistribution of startup outcomes: practically all the returns are\nconcentrated in a few big successes.  The expected value of a startup\nis the percentage chance it's Google.  So to the extent that winning\nis a matter of absolute returns, the super-angels could win practically\nall the battles for individual startups and yet lose the war, if\nthey merely failed to get those few big winners.  And there's a\nchance that could happen, because the top VC funds have better\nbrands, and can also do more for their portfolio companies.  \n[3]Because super-angels make more investments per partner, they have\nless partner per investment.  They can't pay as much attention to\nyou as a VC on your board could.  How much is that extra attention\nworth?  It will vary enormously from one partner to another.  There's\nno consensus yet in the general case.  So for now this is something\nstartups are deciding individually.Till now, VCs' claims about how much value they added were sort of\nlike the government's.  Maybe they made you feel better, but you\nhad no choice in the matter, if you needed money on the scale only\nVCs could supply.  Now that VCs have competitors, that's going to\nput a market price on the help they offer.  The interesting thing\nis, no one knows yet what it will be.Do startups that want to get really big need the sort of advice and\nconnections only the top VCs can supply?  Or would super-angel money\ndo just as well?  The VCs will say you need them, and the super-angels\nwill say you don't.  But the truth is, no one knows yet, not even\nthe VCs and super-angels themselves.   All the super-angels know\nis that their new model seems promising enough to be worth trying,\nand all the VCs know is that it seems promising enough to worry\nabout.RoundsWhatever the outcome, the conflict between VCs and super-angels is\ngood news for founders.  And not just for the obvious reason that\nmore competition for deals means better terms.  The whole shape of\ndeals is changing.One of the biggest differences between angels and VCs is the amount\nof your company they want.  VCs want a lot.  In a series A round\nthey want a third of your company, if they can get it.  They don't\ncare much how much they pay for it, but they want a lot because the\nnumber of series A investments they can do is so small.  In a\ntraditional series A investment, at least one partner from the VC\nfund takes a seat on your board.  \n[4]\n Since board seats last about\n5 years and each partner can't handle more than about 10 at once,\nthat means a VC fund can only do about 2 series A deals per partner\nper year. And that means they need to get as much of the company\nas they can in each one.  You'd have to be a very promising startup\nindeed to get a VC to use up one of his 10 board seats for only a\nfew percent of you.Since angels generally don't take board seats, they don't have this\nconstraint.  They're happy to buy only a few percent of you.  And\nalthough the super-angels are in most respects mini VC funds, they've\nretained this critical property of angels.  They don't take board\nseats, so they don't need a big percentage of your company.Though that means you'll get correspondingly less attention from\nthem, it's good news in other respects.  Founders never really liked\ngiving up as much equity as VCs wanted.  It was a lot of the company\nto give up in one shot.  Most founders doing series A deals would\nprefer to take half as much money for half as much stock, and then\nsee what valuation they could get for the second half of the stock\nafter using the first half of the money to increase its value.  But\nVCs never offered that option.Now startups have another alternative.  Now it's easy to raise angel\nrounds about half the size of series A rounds.  Many of the startups\nwe fund are taking this route, and I predict that will be true of\nstartups in general.A typical big angel round might be $600k on a convertible note with\na valuation cap of $4 million premoney.  Meaning that when the note\nconverts into stock (in a later round, or upon acquisition), the\ninvestors in that round will get .6 / 4.6, or 13% of the company.\nThat's a lot less than the 30 to 40% of the company you usually\ngive up in a series A round if you do it so early.  \n[5]But the advantage of these medium-sized rounds is not just that\nthey cause less dilution.  You also lose less control.  After an\nangel round, the founders almost always still have control of the\ncompany, whereas after a series A round they often don't.  The\ntraditional board structure after a series A round is two founders,\ntwo VCs, and a (supposedly) neutral fifth person.  Plus series A\nterms usually give the investors a veto over various kinds of\nimportant decisions, including selling the company.  Founders usually\nhave a lot of de facto control after a series A, as long as things\nare going well.  But that's not the same as just being able to do\nwhat you want, like you could before.A third and quite significant advantage of angel rounds is that\nthey're less stressful to raise.  Raising a traditional series A\nround has in the past taken weeks, if not months.  When a VC firm\ncan only do 2 deals per partner per year, they're careful about\nwhich they do.  To get a traditional series A round you have to go\nthrough a series of meetings, culminating in a full partner meeting\nwhere the firm as a whole says yes or no.  That's the really scary\npart for founders: not just that series A rounds take so long, but\nat the end of this long process the VCs might still say no.  The\nchance of getting rejected after the full partner meeting averages\nabout 25%.  At some firms it's over 50%.Fortunately for founders, VCs have been getting a lot faster.\nNowadays Valley VCs are more likely to take 2 weeks than 2 months.\nBut they're still not as fast as angels and super-angels, the most\ndecisive of whom sometimes decide in hours.Raising an angel round is not only quicker, but you get feedback\nas it progresses.  An angel round is not an all or nothing thing\nlike a series A.  It's composed of multiple investors with varying\ndegrees of seriousness, ranging from the upstanding ones who commit\nunequivocally to the jerks who give you lines like \"come back to\nme to fill out the round.\" You usually start collecting money from\nthe most committed investors and work your way out toward the\nambivalent ones, whose interest increases as the round fills up.But at each point you know how you're doing.  If investors turn\ncold you may have to raise less, but when investors in an angel\nround turn cold the process at least degrades gracefully, instead\nof blowing up in your face and leaving you with nothing, as happens\nif you get rejected by a VC fund after a full partner meeting.\nWhereas if investors seem hot, you can not only close the round\nfaster, but now that convertible notes are becoming the norm,\nactually raise the price to reflect demand.ValuationHowever, the VCs have a weapon they can use against the super-angels,\nand they have started to use it.   VCs have started making angel-sized\ninvestments too.  The term \"angel round\" doesn't mean that all the\ninvestors in it are angels; it just describes the structure of the\nround.  Increasingly the participants include VCs making investments\nof a hundred thousand or two.  And when VCs invest in angel rounds\nthey can do things that super-angels don't like.  VCs are quite\nvaluation-insensitive in angel rounds\u2014partly because they are\nin general, and partly because they don't care that much about the\nreturns on angel rounds, which they still view mostly as a way to\nrecruit startups for series A rounds later.  So VCs who invest in\nangel rounds can blow up the valuations for angels and super-angels\nwho invest in them. \n[6]Some super-angels seem to care about valuations.  Several turned\ndown YC-funded startups after Demo Day because their valuations\nwere too high.  This was not a problem for the startups; by definition\na high valuation means enough investors were willing to accept it.\nBut it was mysterious to me that the super-angels would quibble\nabout valuations.  Did they not understand that the big returns\ncome from a few big successes, and that it therefore mattered far\nmore which startups you picked than how much you paid for them?After thinking about it for a while and observing certain other\nsigns, I have a theory that explains why the super-angels may be\nsmarter than they seem.  It would make sense for super-angels to\nwant low valuations if they're hoping to invest in startups that\nget bought early.  If you're hoping to hit the next Google, you\nshouldn't care if the valuation is 20 million.  But if you're looking\nfor companies that are going to get bought for 30 million, you care.\nIf you invest at 20 and the company gets bought for 30, you only\nget 1.5x.  You might as well buy Apple.So if some of the super-angels were looking for companies that could\nget acquired quickly, that would explain why they'd care about\nvaluations.  But why would they be looking for those?   Because\ndepending on the meaning of \"quickly,\" it could actually be very\nprofitable.  A company that gets acquired for 30 million is a failure\nto a VC, but it could be a 10x return for an angel, and moreover,\na quick 10x return.  Rate of return is what matters in\ninvesting\u2014not the multiple you get, but the multiple per year.\nIf a super-angel gets 10x in one year, that's a higher rate of\nreturn than a VC could ever hope to get from a company that took 6\nyears to go public.  To get the same rate of return, the VC would\nhave to get a multiple of 10^6\u2014one million x.  Even Google\ndidn't come close to that.So I think at least some super-angels are looking for companies\nthat will get bought.  That's the only rational explanation for\nfocusing on getting the right valuations, instead of the right\ncompanies.  And if so they'll be different to deal with than VCs.\nThey'll be tougher on valuations, but more accommodating if you want\nto sell early.PrognosisWho will win, the super-angels or the VCs?  I think the answer to\nthat is, some of each.  They'll each become more like one another.\nThe super-angels will start to invest larger amounts, and the VCs\nwill gradually figure out ways to make more, smaller investments\nfaster.  A decade from now the players will be hard to tell apart,\nand there will probably be survivors from each group.What does that mean for founders?  One thing it means is that the\nhigh valuations startups are presently getting may not last forever.\nTo the extent that valuations are being driven up by price-insensitive\nVCs, they'll fall again if VCs become more like super-angels and\nstart to become more miserly about valuations.  Fortunately if this\ndoes happen it will take years.The short term forecast is more competition between investors, which\nis good news for you.  The super-angels will try to undermine the\nVCs by acting faster, and the VCs will try to undermine the\nsuper-angels by driving up valuations.  Which for founders will\nresult in the perfect combination: funding rounds that close fast,\nwith high valuations.But remember that to get that combination, your startup will have\nto appeal to both super-angels and VCs.  If you don't seem like you\nhave the potential to go public, you won't be able to use VCs to\ndrive up the valuation of an angel round.There is a danger of having VCs in an angel round: the so-called\nsignalling risk.  If VCs are only doing it in the hope of investing\nmore later, what happens if they don't?  That's a signal to everyone\nelse that they think you're lame.How much should you worry about that?  The seriousness of signalling\nrisk depends on how far along you are.  If by the next time you\nneed to raise money, you have graphs showing rising revenue or\ntraffic month after month, you don't have to worry about any signals\nyour existing investors are sending.  Your results will speak for\nthemselves.  \n[7]Whereas if the next time you need to raise money you won't yet have\nconcrete results, you may need to think more about the message your\ninvestors might send if they don't invest more.  I'm not sure yet\nhow much you have to worry, because this whole phenomenon of VCs\ndoing angel investments is so new. But my instincts tell me you\ndon't have to worry much.  Signalling risk smells like one of those\nthings founders worry about that's not a real problem.  As a rule,\nthe only thing that can kill a good startup is the startup itself.\nStartups hurt themselves way more often than competitors hurt them,\nfor example.  I suspect signalling risk is in this category too.One thing YC-funded startups have been doing to mitigate the risk\nof taking money from VCs in angel rounds is not to take too much\nfrom any one VC.  Maybe that will help, if you have the luxury of\nturning down money.Fortunately, more and more startups will.  After decades of competition\nthat could best be described as intramural, the startup funding\nbusiness is finally getting some real competition.  That should\nlast several years at least, and maybe a lot longer. Unless there's\nsome huge market crash, the next couple years are going to be a\ngood time for startups to raise money.  And that's exciting because\nit means lots more startups will happen.\nNotes[1]\nI've also heard them called \"Mini-VCs\" and \"Micro-VCs.\" I\ndon't know which name will stick.There were a couple predecessors.  Ron Conway had angel funds\nstarting in the 1990s, and in some ways First Round Capital is closer to a\nsuper-angel than a VC fund.[2]\nIt wouldn't cut their overall returns tenfold, because investing\nlater would probably (a) cause them to lose less on investments\nthat failed, and (b) not allow them to get as large a percentage\nof startups as they do now.  So it's hard to predict precisely what\nwould happen to their returns.[3]\nThe brand of an investor derives mostly from the success of\ntheir portfolio companies.  The top VCs thus have a big brand\nadvantage over the super-angels.  They could make it self-perpetuating\nif they used it to get all the best new startups.  But I don't think\nthey'll be able to.  To get all the best startups, you have to do\nmore than make them want you.  You also have to want them; you have\nto recognize them when you see them, and that's much harder.\nSuper-angels will snap up stars that VCs miss.  And that will cause\nthe brand gap between the top VCs and the super-angels gradually\nto erode.[4]\nThough in a traditional series A round VCs put two partners\non your board, there are signs now that VCs may begin to conserve\nboard seats by switching to what used to be considered an angel-round\nboard, consisting of two founders and one VC.  Which is also to the\nfounders' advantage if it means they still control the company.[5]\nIn a series A round, you usually have to give up more than\nthe actual amount of stock the VCs buy, because they insist you\ndilute yourselves to set aside an \"option pool\" as well.  I predict\nthis practice will gradually disappear though.[6]\nThe best thing for founders, if they can get it, is a convertible\nnote with no valuation cap at all.  In that case the money invested\nin the angel round just converts into stock at the valuation of the\nnext round, no matter how large.  Angels and super-angels tend not\nto like uncapped notes. They have no idea how much of the company\nthey're buying.  If the company does well and the valuation of the\nnext round is high, they may end up with only a sliver of it.  So\nby agreeing to uncapped notes, VCs who don't care about valuations\nin angel rounds can make offers that super-angels hate to match.[7]\nObviously signalling risk is also not a problem if you'll\nnever need to raise more money.  But startups are often mistaken\nabout that.Thanks to Sam Altman, John Bautista, Patrick Collison, James\nLindenbaum, Reid Hoffman, Jessica Livingston and Harj Taggar\nfor reading drafts\nof this.November 2022Since I was about 9 I've been puzzled by the apparent contradiction\nbetween being made of matter that behaves in a predictable way, and\nthe feeling that I could choose to do whatever I wanted. At the\ntime I had a self-interested motive for exploring the question. At\nthat age (like most succeeding ages) I was always in trouble with\nthe authorities, and it seemed to me that there might possibly be\nsome way to get out of trouble by arguing that I wasn't responsible\nfor my actions. I gradually lost hope of that, but the puzzle\nremained: How do you reconcile being a machine made of matter with\nthe feeling that you're free to choose what you do?\n[1]The best way to explain the answer may be to start with a slightly\nwrong version, and then fix it. The wrong version is: You can do\nwhat you want, but you can't want what you want. Yes, you can control\nwhat you do, but you'll do what you want, and you can't control\nthat.The reason this is mistaken is that people do sometimes change what\nthey want. People who don't want to want something \u2014 drug addicts,\nfor example \u2014 can sometimes make themselves stop wanting it. And\npeople who want to want something \u2014 who want to like classical\nmusic, or broccoli \u2014 sometimes succeed.So we modify our initial statement: You can do what you want, but\nyou can't want to want what you want.That's still not quite true. It's possible to change what you want\nto want. I can imagine someone saying \"I decided to stop wanting\nto like classical music.\" But we're getting closer to the truth.\nIt's rare for people to change what they want to want, and the more\n\"want to\"s we add, the rarer it gets.We can get arbitrarily close to a true statement by adding more \"want\nto\"s in much the same way we can get arbitrarily close to 1 by adding\nmore 9s to a string of 9s following a decimal point. In practice\nthree or four \"want to\"s must surely be enough. It's hard even to\nenvision what it would mean to change what you want to want to want\nto want, let alone actually do it.So one way to express the correct answer is to use a regular\nexpression. You can do what you want, but there's some statement\nof the form \"you can't (want to)* want what you want\" that's true.\nUltimately you get back to a want that you don't control.\n[2]\nNotes[1]\nI didn't know when I was 9 that matter might behave randomly,\nbut I don't think it affects the problem much. Randomness destroys\nthe ghost in the machine as effectively as determinism.[2]\nIf you don't like using an expression, you can make the same\npoint using higher-order desires: There is some n such that you\ndon't control your nth-order desires.\nThanks to Trevor Blackwell,\nJessica Livingston, Robert Morris, and\nMichael Nielsen for reading drafts of this.October 2015This will come as a surprise to a lot of people, but in some cases\nit's possible to detect bias in a selection process without knowing\nanything about the applicant pool.  Which is exciting because among\nother things it means third parties can use this technique to detect\nbias whether those doing the selecting want them to or not.You can use this technique whenever (a) you have at least\na random sample of the applicants that were selected, (b) their\nsubsequent performance is measured, and (c) the groups of\napplicants you're comparing have roughly equal distribution of ability.How does it work?  Think about what it means to be biased.  What\nit means for a selection process to be biased against applicants\nof type x is that it's harder for them to make it through.  Which\nmeans applicants of type x have to be better to get selected than\napplicants not of type x.\n[1]\nWhich means applicants of type x\nwho do make it through the selection process will outperform other\nsuccessful applicants.  And if the performance of all the successful\napplicants is measured, you'll know if they do.Of course, the test you use to measure performance must be a valid\none.  And in particular it must not be invalidated by the bias you're\ntrying to measure.\nBut there are some domains where performance can be measured, and\nin those detecting bias is straightforward. Want to know if the\nselection process was biased against some type of applicant?  Check\nwhether they outperform the others.  This is not just a heuristic\nfor detecting bias.  It's what bias means.For example, many suspect that venture capital firms are biased\nagainst female founders. This would be easy to detect: among their\nportfolio companies, do startups with female founders outperform\nthose without?  A couple months ago, one VC firm (almost certainly\nunintentionally) published a study showing bias of this type. First\nRound Capital found that among its portfolio companies, startups\nwith female founders outperformed\nthose without by 63%. \n[2]The reason I began by saying that this technique would come as a\nsurprise to many people is that we so rarely see analyses of this\ntype.  I'm sure it will come as a surprise to First Round that they\nperformed one. I doubt anyone there realized that by limiting their\nsample to their own portfolio, they were producing a study not of\nstartup trends but of their own biases when selecting companies.I predict we'll see this technique used more in the future.  The\ninformation needed to conduct such studies is increasingly available.\nData about who applies for things is usually closely guarded by the\norganizations selecting them, but nowadays data about who gets\nselected is often publicly available to anyone who takes the trouble\nto aggregate it.\nNotes[1]\nThis technique wouldn't work if the selection process looked\nfor different things from different types of applicants\u2014for\nexample, if an employer hired men based on their ability but women\nbased on their appearance.[2]\nAs Paul Buchheit points out, First Round excluded their most \nsuccessful investment, Uber, from the study.  And while it \nmakes sense to exclude outliers from some types of studies, \nstudies of returns from startup investing, which is all about \nhitting outliers, are not one of them.\nThanks to Sam Altman, Jessica Livingston, and Geoff Ralston for reading\ndrafts of this.\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nMarch 2008, rev. June 2008Technology tends to separate normal from natural.  Our bodies\nweren't designed to eat the foods that people in rich countries eat, or\nto get so little exercise.  \nThere may be a similar problem with the way we work: \na normal job may be as bad for us intellectually as white flour\nor sugar is for us physically.I began to suspect this after spending several years working \nwith startup founders.  I've now worked with over 200 of them, and I've\nnoticed a definite difference between programmers working on their\nown startups and those working for large organizations.\nI wouldn't say founders seem happier, necessarily;\nstarting a startup can be very stressful. Maybe the best way to put\nit is to say that they're happier in the sense that your body is\nhappier during a long run than sitting on a sofa eating\ndoughnuts.Though they're statistically abnormal, startup founders seem to be\nworking in a way that's more natural for humans.I was in Africa last year and saw a lot of animals in the wild that\nI'd only seen in zoos before. It was remarkable how different they\nseemed. Particularly lions. Lions in the wild seem about ten times\nmore alive. They're like different animals. I suspect that working\nfor oneself feels better to humans in much the same way that living\nin the wild must feel better to a wide-ranging predator like a lion.\nLife in a zoo is easier, but it isn't the life they were designed\nfor.\nTreesWhat's so unnatural about working for a big company?  The root of\nthe problem is that humans weren't meant to work in such large\ngroups.Another thing you notice when you see animals in the wild is that\neach species thrives in groups of a certain size.  A herd of impalas\nmight have 100 adults; baboons maybe 20; lions rarely 10.  Humans\nalso seem designed to work in groups, and what I've read about\nhunter-gatherers accords with research on organizations and my own\nexperience to suggest roughly what the ideal size is: groups of 8\nwork well; by 20 they're getting hard to manage; and a group of 50\nis really unwieldy.\n[1]\nWhatever the upper limit is, we are clearly not meant to work in\ngroups of several hundred.  And yet\u2014for reasons having more\nto do with technology than human nature\u2014a great many people\nwork for companies with hundreds or thousands of employees.Companies know groups that large wouldn't work, so they divide\nthemselves into units small enough to work together.  But to\ncoordinate these they have to introduce something new: bosses.These smaller groups are always arranged in a tree structure.  Your\nboss is the point where your group attaches to the tree.  But when\nyou use this trick for dividing a large group into smaller ones,\nsomething strange happens that I've never heard anyone mention\nexplicitly.  In the group one level up from yours, your boss\nrepresents your entire group.  A group of 10 managers is not merely\na group of 10 people working together in the usual way.  It's really\na group of groups.  Which means for a group of 10 managers to work\ntogether as if they were simply a group of 10 individuals, the group\nworking for each manager would have to work as if they were a single\nperson\u2014the workers and manager would each share only one\nperson's worth of freedom between them.In practice a group of people are never able to act as if they were\none person.  But in a large organization divided into groups in\nthis way, the pressure is always in that direction.  Each group\ntries its best to work as if it were the small group of individuals\nthat humans were designed to work in.  That was the point of creating\nit.  And when you propagate that constraint, the result is that\neach person gets freedom of action in inverse proportion to the\nsize of the entire tree.\n[2]Anyone who's worked for a large organization has felt this.  You\ncan feel the difference between working for a company with 100\nemployees and one with 10,000, even if your group has only 10 people.\nCorn SyrupA group of 10 people within a large organization is a kind of fake\ntribe.  The number of people you interact with is about right.  But\nsomething is missing: individual initiative.  Tribes of hunter-gatherers\nhave much more freedom.  The leaders have a little more power than other\nmembers of the tribe, but they don't generally tell them what to\ndo and when the way a boss can.It's not your boss's fault.  The real problem is that in the group\nabove you in the hierarchy, your entire group is one virtual person.\nYour boss is just the way that constraint is imparted to you.So working in a group of 10 people within a large organization feels\nboth right and wrong at the same time.   On the surface it feels\nlike the kind of group you're meant to work in, but something major\nis missing.  A job at a big company is like high fructose corn\nsyrup: it has some of the qualities of things you're meant to like,\nbut is disastrously lacking in others.Indeed, food is an excellent metaphor to explain what's wrong with\nthe usual sort of job.For example, working for a big company is the default thing to do,\nat least for programmers.  How bad could it be?  Well, food shows\nthat pretty clearly.  If you were dropped at a random point in\nAmerica today, nearly all the food around you would be bad for you.\nHumans were not designed to eat white flour, refined sugar, high\nfructose corn syrup, and hydrogenated vegetable oil.  And yet if\nyou analyzed the contents of the average grocery store you'd probably\nfind these four ingredients accounted for most of the calories.\n\"Normal\" food is terribly bad for you.  The only people who eat\nwhat humans were actually designed to eat are a few Birkenstock-wearing\nweirdos in Berkeley.If \"normal\" food is so bad for us, why is it so common?  There are\ntwo main reasons. One is that it has more immediate appeal.  You\nmay feel lousy an hour after eating that pizza, but eating the first\ncouple bites feels great.  The other is economies of scale.\nProducing junk food scales; producing fresh vegetables doesn't.\nWhich means (a) junk food can be very cheap, and (b) it's worth\nspending a lot to market it.If people have to choose between something that's cheap, heavily\nmarketed, and appealing in the short term, and something that's\nexpensive, obscure, and appealing in the long term, which do you\nthink most will choose?It's the same with work.  The average MIT graduate wants to work\nat Google or Microsoft, because it's a recognized brand, it's safe,\nand they'll get paid a good salary right away.  It's the job\nequivalent of the pizza they had for lunch.  The drawbacks will\nonly become apparent later, and then only in a vague sense of\nmalaise.And founders and early employees of startups, meanwhile, are like\nthe Birkenstock-wearing weirdos of Berkeley:  though a tiny minority\nof the population, they're the ones living as humans are meant to.\nIn an artificial world, only extremists live naturally.\nProgrammersThe restrictiveness of big company jobs is particularly hard on\nprogrammers, because the essence of programming is to build new\nthings.  Sales people make much the same pitches every day; support\npeople answer much the same questions; but once you've written a\npiece of code you don't need to write it again.  So a programmer\nworking as programmers are meant to is always making new things.\nAnd when you're part of an organization whose structure gives each\nperson freedom in inverse proportion to the size of the tree, you're\ngoing to face resistance when you do something new.This seems an inevitable consequence of bigness.  It's true even\nin the smartest companies.  I was talking recently to a founder who\nconsidered starting a startup right out of college, but went to\nwork for Google instead because he thought he'd learn more there.\nHe didn't learn as much as he expected.  Programmers learn by doing,\nand most of the things he wanted to do, he couldn't\u2014sometimes\nbecause the company wouldn't let him, but often because the company's\ncode wouldn't let him.  Between the drag of legacy code, the overhead\nof doing development in such a large organization, and the restrictions\nimposed by interfaces owned by other groups, he could only try a\nfraction of the things he would have liked to.  He said he has\nlearned much more in his own startup, despite the fact that he has\nto do all the company's errands as well as programming, because at\nleast when he's programming he can do whatever he wants.An obstacle downstream propagates upstream.  If you're not allowed\nto implement new ideas, you stop having them.  And vice versa: when\nyou can do whatever you want, you have more ideas about what to do.\nSo working for yourself makes your brain more powerful in the same\nway a low-restriction exhaust system makes an engine more powerful.Working for yourself doesn't have to mean starting a startup, of\ncourse.  But a programmer deciding between a regular job at a big\ncompany and their own startup is probably going to learn more doing\nthe startup.You can adjust the amount of freedom you get by scaling the size\nof company you work for.  If you start the company, you'll have the\nmost freedom.  If you become one of the first 10 employees you'll\nhave almost as much freedom as the founders.  Even a company with\n100 people will feel different from one with 1000.Working for a small company doesn't ensure freedom.  The tree\nstructure of large organizations sets an upper bound on freedom,\nnot a lower bound.  The head of a small company may still choose\nto be a tyrant.  The point is that a large organization is compelled\nby its structure to be one.\nConsequencesThat has real consequences for both organizations and individuals.\nOne is that companies will inevitably slow down as they grow larger,\nno matter how hard they try to keep their startup mojo.  It's a\nconsequence of the tree structure that every large organization is\nforced to adopt.Or rather, a large organization could only avoid slowing down if\nthey avoided tree structure.  And since human nature limits the\nsize of group that can work together, the only way I can imagine\nfor larger groups to avoid tree structure would be to have no\nstructure: to have each group actually be independent, and to work\ntogether the way components of a market economy do.That might be worth exploring.  I suspect there are already some\nhighly partitionable businesses that lean this way.  But I don't\nknow any technology companies that have done it.There is one thing companies can do short of structuring themselves\nas sponges:  they can stay small.  If I'm right, then it really\npays to keep a company as small as it can be at every stage.\nParticularly a technology company.  Which means it's doubly important\nto hire the best people.  Mediocre hires hurt you twice: they get\nless done, but they also make you big, because you need more of\nthem to solve a given problem.For individuals the upshot is the same: aim small.  It will always\nsuck to work for large organizations, and the larger the organization,\nthe more it will suck.In an essay I wrote a couple years ago \nI advised graduating seniors\nto work for a couple years for another company before starting their\nown.  I'd modify that now.  Work for another company if you want\nto, but only for a small one, and if you want to start your own\nstartup, go ahead.The reason I suggested college graduates not start startups immediately\nwas that I felt most would fail.  And they will.  But ambitious\nprogrammers are better off doing their own thing and failing than\ngoing to work at a big company.  Certainly they'll learn more.  They\nmight even be better off financially.  A lot of people in their\nearly twenties get into debt, because their expenses grow even\nfaster than the salary that seemed so high when they left school.\nAt least if you start a startup and fail your net worth will be\nzero rather than negative.  \n[3]We've now funded so many different types of founders that we have\nenough data to see patterns, and there seems to be no benefit from\nworking for a big company.  The people who've worked for a few years\ndo seem better than the ones straight out of college, but only\nbecause they're that much older.The people who come to us from big companies often seem kind of\nconservative.  It's hard to say how much is because big companies\nmade them that way, and how much is the natural conservatism that\nmade them work for the big companies in the first place.  But\ncertainly a large part of it is learned.  I know because I've seen\nit burn off.Having seen that happen so many times is one of the things that\nconvinces me that working for oneself, or at least for a small\ngroup, is the natural way for programmers to live.  Founders arriving\nat Y Combinator often have the downtrodden air of refugees.  Three\nmonths later they're transformed: they have so much more \nconfidence\nthat they seem as if they've grown several inches taller. \n[4]\nStrange as this sounds, they seem both more worried and happier at the same\ntime.  Which is exactly how I'd describe the way lions seem in the\nwild.Watching employees get transformed into founders makes it clear\nthat the difference between the two is due mostly to environment\u2014and\nin particular that the environment in big companies is toxic to\nprogrammers.   In the first couple weeks of working on their own\nstartup they seem to come to life, because finally they're working\nthe way people are meant to.Notes[1]\nWhen I talk about humans being meant or designed to live a\ncertain way, I mean by evolution.[2]\nIt's not only the leaves who suffer.  The constraint propagates\nup as well as down.  So managers are constrained too; instead of\njust doing things, they have to act through subordinates.[3]\nDo not finance your startup with credit cards.  Financing a\nstartup with debt is usually a stupid move, and credit card debt\nstupidest of all.  Credit card debt is a bad idea, period.  It is\na trap set by evil companies for the desperate and the foolish.[4]\nThe founders we fund used to be younger (initially we encouraged\nundergrads to apply), and the first couple times I saw this I used\nto wonder if they were actually getting physically taller.Thanks to Trevor Blackwell, Ross Boucher, Aaron Iba, Abby\nKirigin, Ivan Kirigin, Jessica Livingston, and Robert Morris for\nreading drafts of this.January 2003(This article is derived from a keynote talk at the fall 2002 meeting\nof NEPLS.)Visitors to this country are often surprised to find that\nAmericans like to begin a conversation by asking \"what do you do?\"\nI've never liked this question.  I've rarely had a\nneat answer to it.  But I think I have finally solved the problem.\nNow, when someone asks me what I do, I look them straight\nin the eye and say \"I'm designing a \nnew dialect of Lisp.\"   \nI recommend this answer to anyone who doesn't like being asked what\nthey do.  The conversation will turn immediately to other topics.I don't consider myself to be doing research on programming languages.\nI'm just designing one, in the same way that someone might design\na building or a chair or a new typeface.\nI'm not trying to discover anything new.  I just want\nto make a language that will be good to program in.  In some ways,\nthis assumption makes life a lot easier.The difference between design and research seems to be a question\nof new versus good.  Design doesn't have to be new, but it has to  \nbe good.  Research doesn't have to be good, but it has to be new.\nI think these two paths converge at the top: the best design\nsurpasses its predecessors by using new ideas, and the best research\nsolves problems that are not only new, but actually worth solving.\nSo ultimately we're aiming for the same destination, just approaching\nit from different directions.What I'm going to talk about today is what your target looks like\nfrom the back.  What do you do differently when you treat\nprogramming languages as a design problem instead of a research topic?The biggest difference is that you focus more on the user.\nDesign begins by asking, who is this\nfor and what do they need from it?  A good architect,\nfor example, does not begin by creating a design that he then\nimposes on the users, but by studying the intended users and figuring\nout what they need.Notice I said \"what they need,\" not \"what they want.\"  I don't mean\nto give the impression that working as a designer means working as \na sort of short-order cook, making whatever the client tells you\nto.  This varies from field to field in the arts, but\nI don't think there is any field in which the best work is done by\nthe people who just make exactly what the customers tell them to.The customer is always right in\nthe sense that the measure of good design is how well it works\nfor the user.  If you make a novel that bores everyone, or a chair\nthat's horribly uncomfortable to sit in, then you've done a bad\njob, period.  It's no defense to say that the novel or the chair  \nis designed according to the most advanced theoretical principles.And yet, making what works for the user doesn't mean simply making\nwhat the user tells you to.  Users don't know what all the choices\nare, and are often mistaken about what they really want.The answer to the paradox, I think, is that you have to design\nfor the user, but you have to design what the user needs, not simply  \nwhat he says he wants.\nIt's much like being a doctor.  You can't just treat a patient's\nsymptoms.  When a patient tells you his symptoms, you have to figure\nout what's actually wrong with him, and treat that.This focus on the user is a kind of axiom from which most of the\npractice of good design can be derived, and around which most design\nissues center.If good design must do what the user needs, who is the user?  When\nI say that design must be for users, I don't mean to imply that good \ndesign aims at some kind of  \nlowest common denominator.  You can pick any group of users you\nwant.  If you're designing a tool, for example, you can design it\nfor anyone from beginners to experts, and what's good design\nfor one group might be bad for another.  The point\nis, you have to pick some group of users.  I don't think you can\neven talk about good or bad design except with\nreference to some intended user.You're most likely to get good design if the intended users include\nthe designer himself.  When you design something\nfor a group that doesn't include you, it tends to be for people\nyou consider to be less sophisticated than you, not more sophisticated.That's a problem, because looking down on the user, however benevolently,\nseems inevitably to corrupt the designer.\nI suspect that very few housing\nprojects in the US were designed by architects who expected to live\nin them.   You can see the same thing\nin programming languages.  C, Lisp, and Smalltalk were created for\ntheir own designers to use.  Cobol, Ada, and Java, were created   \nfor other people to use.If you think you're designing something for idiots, the odds are\nthat you're not designing something good, even for idiots.\nEven if you're designing something for the most sophisticated\nusers, though, you're still designing for humans.  It's different \nin research.  In math you\ndon't choose abstractions because they're\neasy for humans to understand; you choose whichever make the\nproof shorter.  I think this is true for the sciences generally.\nScientific ideas are not meant to be ergonomic.Over in the arts, things are very different.  Design is\nall about people.  The human body is a strange\nthing, but when you're designing a chair,\nthat's what you're designing for, and there's no way around it.\nAll the arts have to pander to the interests and limitations\nof humans.   In painting, for example, all other things being\nequal a painting with people in it will be more interesting than\none without.  It is not merely an accident of history that\nthe great paintings of the Renaissance are all full of people.\nIf they hadn't been, painting as a medium wouldn't have the prestige\nthat it does.Like it or not, programming languages are also for people,\nand I suspect the human brain is just as lumpy and idiosyncratic\nas the human body.  Some ideas are easy for people to grasp\nand some aren't.  For example, we seem to have a very limited\ncapacity for dealing with detail.  It's this fact that makes\nprograming languages a good idea in the first place; if we\ncould handle the detail, we could just program in machine\nlanguage.Remember, too, that languages are not\nprimarily a form for finished programs, but something that\nprograms have to be developed in.  Anyone in the arts could\ntell you that you might want different mediums for the\ntwo situations.  Marble, for example, is a nice, durable\nmedium for finished ideas, but a hopelessly inflexible one\nfor developing new ideas.A program, like a proof,\nis a pruned version of a tree that in the past has had\nfalse starts branching off all over it.  So the test of\na language is not simply how clean the finished program looks\nin it, but how clean the path to the finished program was.\nA design choice that gives you elegant finished programs\nmay not give you an elegant design process.  For example, \nI've written a few macro-defining macros full of nested\nbackquotes that look now like little gems, but writing them\ntook hours of the ugliest trial and error, and frankly, I'm still\nnot entirely sure they're correct.We often act as if the test of a language were how good\nfinished programs look in it.\nIt seems so convincing when you see the same program\nwritten in two languages, and one version is much shorter.\nWhen you approach the problem from the direction of the\narts, you're less likely to depend on this sort of\ntest.  You don't want to end up with a programming\nlanguage like marble.For example, it is a huge win in developing software to\nhave an interactive toplevel, what in Lisp is called a\nread-eval-print loop.  And when you have one this has\nreal effects on the design of the language.  It would not\nwork well for a language where you have to declare\nvariables before using them, for example.  When you're\njust typing expressions into the toplevel, you want to be \nable to set x to some value and then start doing things\nto x.  You don't want to have to declare the type of x\nfirst.  You may dispute either of the premises, but if\na language has to have a toplevel to be convenient, and\nmandatory type declarations are incompatible with a\ntoplevel, then no language that makes type declarations  \nmandatory could be convenient to program in.In practice, to get good design you have to get close, and stay\nclose, to your users.  You have to calibrate your ideas on actual\nusers constantly, especially in the beginning.  One of the reasons\nJane Austen's novels are so good is that she read them out loud to\nher family.  That's why she never sinks into self-indulgently arty\ndescriptions of landscapes,\nor pretentious philosophizing.  (The philosophy's there, but it's\nwoven into the story instead of being pasted onto it like a label.)\nIf you open an average \"literary\" novel and imagine reading it out loud\nto your friends as something you'd written, you'll feel all too\nkeenly what an imposition that kind of thing is upon the reader.In the software world, this idea is known as Worse is Better.\nActually, there are several ideas mixed together in the concept of\nWorse is Better, which is why people are still arguing about\nwhether worse\nis actually better or not.  But one of the main ideas in that\nmix is that if you're building something new, you should get a\nprototype in front of users as soon as possible.The alternative approach might be called the Hail Mary strategy.\nInstead of getting a prototype out quickly and gradually refining\nit, you try to create the complete, finished, product in one long\ntouchdown pass.  As far as I know, this is a\nrecipe for disaster.  Countless startups destroyed themselves this\nway during the Internet bubble.  I've never heard of a case\nwhere it worked.What people outside the software world may not realize is that\nWorse is Better is found throughout the arts.\nIn drawing, for example, the idea was discovered during the\nRenaissance.  Now almost every drawing teacher will tell you that\nthe right way to get an accurate drawing is not to\nwork your way slowly around the contour of an object, because errors will\naccumulate and you'll find at the end that the lines don't meet.\nInstead you should draw a few quick lines in roughly the right place,\nand then gradually refine this initial sketch.In most fields, prototypes\nhave traditionally been made out of different materials.\nTypefaces to be cut in metal were initially designed  \nwith a brush on paper.  Statues to be cast in bronze   \nwere modelled in wax.  Patterns to be embroidered on tapestries\nwere drawn on paper with ink wash.  Buildings to be\nconstructed from stone were tested on a smaller scale in wood.What made oil paint so exciting, when it\nfirst became popular in the fifteenth century, was that you\ncould actually make the finished work from the prototype.\nYou could make a preliminary drawing if you wanted to, but you\nweren't held to it; you could work out all the details, and\neven make major changes, as you finished the painting.You can do this in software too.  A prototype doesn't have to\nbe just a model; you can refine it into the finished product.\nI think you should always do this when you can.  It lets you\ntake advantage of new insights you have along the way.  But\nperhaps even more important, it's good for morale.Morale is key in design.  I'm surprised people\ndon't talk more about it.  One of my first\ndrawing teachers told me: if you're bored when you're\ndrawing something, the drawing will look boring.\nFor example, suppose you have to draw a building, and you\ndecide to draw each brick individually.  You can do this\nif you want, but if you get bored halfway through and start\nmaking the bricks mechanically instead of observing each one,   \nthe drawing will look worse than if you had merely suggested\nthe bricks.Building something by gradually refining a prototype is good\nfor morale because it keeps you engaged.  In software, my  \nrule is: always have working code.  If you're writing\nsomething that you'll be able to test in an hour, then you\nhave the prospect of an immediate reward to motivate you.\nThe same is true in the arts, and particularly in oil painting.\nMost painters start with a blurry sketch and gradually\nrefine it.\nIf you work this way, then in principle\nyou never have to end the day with something that actually\nlooks unfinished.  Indeed, there is even a saying among\npainters: \"A painting is never finished, you just stop\nworking on it.\"  This idea will be familiar to anyone who\nhas worked on software.Morale is another reason that it's hard to design something\nfor an unsophisticated user.   It's hard to stay interested in\nsomething you don't like yourself.  To make something  \ngood, you have to be thinking, \"wow, this is really great,\"\nnot \"what a piece of shit; those fools will love it.\"Design means making things for humans.  But it's not just the\nuser who's human.  The designer is human too.Notice all this time I've been talking about \"the designer.\"\nDesign usually has to be under the control of a single person to\nbe any good.   And yet it seems to be possible for several people\nto collaborate on a research project.  This seems to\nme one of the most interesting differences between research and\ndesign.There have been famous instances of collaboration in the arts,\nbut most of them seem to have been cases of molecular bonding rather\nthan nuclear fusion.  In an opera it's common for one person to\nwrite the libretto and another to write the music.   And during the Renaissance, \njourneymen from northern\nEurope were often employed to do the landscapes in the\nbackgrounds of Italian paintings.  But these aren't true collaborations.\nThey're more like examples of Robert Frost's\n\"good fences make good neighbors.\"  You can stick instances\nof good design together, but within each individual project,\none person has to be in control.I'm not saying that good design requires that one person think\nof everything.  There's nothing more valuable than the advice\nof someone whose judgement you trust.  But after the talking is\ndone, the decision about what to do has to rest with one person.Why is it that research can be done by collaborators and  \ndesign can't?  This is an interesting question.  I don't \nknow the answer.  Perhaps,\nif design and research converge, the best research is also\ngood design, and in fact can't be done by collaborators.\nA lot of the most famous scientists seem to have worked alone.\nBut I don't know enough to say whether there\nis a pattern here.  It could be simply that many famous scientists\nworked when collaboration was less common.Whatever the story is in the sciences, true collaboration\nseems to be vanishingly rare in the arts.  Design by committee is a\nsynonym for bad design.  Why is that so?  Is there some way to\nbeat this limitation?I'm inclined to think there isn't-- that good design requires\na dictator.  One reason is that good design has to   \nbe all of a piece.  Design is not just for humans, but\nfor individual humans.  If a design represents an idea that  \nfits in one person's head, then the idea will fit in the user's\nhead too.Related:Aaron Swartz created a scraped\nfeed\nof the essays page.December 2001 (rev. May 2002)\n\n(This article came about in response to some questions on\nthe LL1 mailing list.  It is now\nincorporated in Revenge of the Nerds.)When McCarthy designed Lisp in the late 1950s, it was\na radical departure from existing languages,\nthe most important of which was Fortran.Lisp embodied nine new ideas:\n1. Conditionals.  A conditional is an if-then-else\nconstruct.  We take these for granted now.  They were \ninvented\nby McCarthy in the course of developing Lisp. \n(Fortran at that time only had a conditional\ngoto, closely based on the branch instruction in the \nunderlying hardware.)  McCarthy, who was on the Algol committee, got\nconditionals into Algol, whence they spread to most other\nlanguages.2. A function type. In Lisp, functions are first class \nobjects-- they're a data type just like integers, strings,\netc, and have a literal representation, can be stored in variables,\ncan be passed as arguments, and so on.3. Recursion.  Recursion existed as a mathematical concept\nbefore Lisp of course, but Lisp was the first programming language to support\nit.  (It's arguably implicit in making functions first class\nobjects.)4. A new concept of variables.  In Lisp, all variables\nare effectively pointers. Values are what\nhave types, not variables, and assigning or binding\nvariables means copying pointers, not what they point to.5. Garbage-collection.6. Programs composed of expressions. Lisp programs are \ntrees of expressions, each of which returns a value.  \n(In some Lisps expressions\ncan return multiple values.)  This is in contrast to Fortran\nand most succeeding languages, which distinguish between\nexpressions and statements.It was natural to have this\ndistinction in Fortran because (not surprisingly in a language\nwhere the input format was punched cards) the language was\nline-oriented.  You could not nest statements.  And\nso while you needed expressions for math to work, there was\nno point in making anything else return a value, because\nthere could not be anything waiting for it.This limitation\nwent away with the arrival of block-structured languages,\nbut by then it was too late. The distinction between\nexpressions and statements was entrenched.  It spread from \nFortran into Algol and thence to both their descendants.When a language is made entirely of expressions, you can\ncompose expressions however you want.  You can say either\n(using Arc syntax)(if foo (= x 1) (= x 2))or(= x (if foo 1 2))7. A symbol type.  Symbols differ from strings in that\nyou can test equality by comparing a pointer.8. A notation for code using trees of symbols.9. The whole language always available.  \nThere is\nno real distinction between read-time, compile-time, and runtime.\nYou can compile or run code while reading, read or run code\nwhile compiling, and read or compile code at runtime.Running code at read-time lets users reprogram Lisp's syntax;\nrunning code at compile-time is the basis of macros; compiling\nat runtime is the basis of Lisp's use as an extension\nlanguage in programs like Emacs; and reading at runtime\nenables programs to communicate using s-expressions, an\nidea recently reinvented as XML.\nWhen Lisp was first invented, all these ideas were far\nremoved from ordinary programming practice, which was\ndictated largely by the hardware available in the late 1950s.Over time, the default language, embodied\nin a succession of popular languages, has\ngradually evolved toward Lisp.  1-5 are now widespread.\n6 is starting to appear in the mainstream.\nPython has a form of 7, though there doesn't seem to be\nany syntax for it.  \n8, which (with 9) is what makes Lisp macros\npossible, is so far still unique to Lisp,\nperhaps because (a) it requires those parens, or something \njust as bad, and (b) if you add that final increment of power, \nyou can no \nlonger claim to have invented a new language, but only\nto have designed a new dialect of Lisp ; -)Though useful to present-day programmers, it's\nstrange to describe Lisp in terms of its\nvariation from the random expedients other languages\nadopted.  That was not, probably, how McCarthy\nthought of it.  Lisp wasn't designed to fix the mistakes\nin Fortran; it came about more as the byproduct of an\nattempt to axiomatize computation.May 2007People who worry about the increasing gap between rich and poor\ngenerally look back on the mid twentieth century as a golden age.\nIn those days we had a large number of high-paying union manufacturing\njobs that boosted the median income.  I wouldn't quite call the\nhigh-paying union job a myth, but I think people who dwell on it\nare reading too much into it.Oddly enough, it was working with startups that made me realize\nwhere the high-paying union job came from.  In a rapidly growing\nmarket, you don't worry too much about efficiency.  It's more\nimportant to grow fast.  If there's some mundane problem getting\nin your way, and there's a simple solution that's somewhat expensive,\njust take it and get on with more important things.  EBay didn't\nwin by paying less for servers than their competitors.Difficult though it may be to imagine now, manufacturing was a\ngrowth industry in the mid twentieth century.  This was an era when\nsmall firms making everything from cars to candy were getting\nconsolidated into a new kind of corporation with national reach and\nhuge economies of scale.  You had to grow fast or die.  Workers\nwere for these companies what servers are for an Internet startup.\nA reliable supply was more important than low cost.If you looked in the head of a 1950s auto executive, the attitude\nmust have been: sure, give 'em whatever they ask for, so long as\nthe new model isn't delayed.In other words, those workers were not paid what their work was\nworth.  Circumstances being what they were, companies would have\nbeen stupid to insist on paying them so little.If you want a less controversial example of this phenomenon, ask\nanyone who worked as a consultant building web sites during the\nInternet Bubble.  In the late nineties you could get paid huge sums\nof money for building the most trivial things.  And yet does anyone\nwho was there have any expectation those days will ever return?  I\ndoubt it.  Surely everyone realizes that was just a temporary\naberration.The era of labor unions seems to have been the same kind of aberration, \njust spread\nover a longer period, and mixed together with a lot of ideology\nthat prevents people from viewing it with as cold an eye as they\nwould something like consulting during the Bubble.Basically, unions were just Razorfish.People who think the labor movement was the creation of heroic union\norganizers have a problem to explain: why are unions shrinking now?\nThe best they can do is fall back on the default explanation of\npeople living in fallen civilizations.  Our ancestors were giants.\nThe workers of the early twentieth century must have had a moral\ncourage that's lacking today.In fact there's a simpler explanation.  The early twentieth century\nwas just a fast-growing startup overpaying for infrastructure.  And\nwe in the present are not a fallen people, who have abandoned\nwhatever mysterious high-minded principles produced the high-paying\nunion job.  We simply live in a time when the fast-growing companies\noverspend on different things.\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nJanuary 2006To do something well you have to like it.   That idea is not exactly\nnovel.  We've got it down to four words: \"Do what you love.\"  But\nit's not enough just to tell people that.  Doing what you love is\ncomplicated.The very idea is foreign to what most of us learn as kids.  When I\nwas a kid, it seemed as if work and fun were opposites by definition.\nLife had two states: some of the time adults were making you do\nthings, and that was called work; the rest of the time you could\ndo what you wanted, and that was called playing.  Occasionally the\nthings adults made you do were fun, just as, occasionally, playing\nwasn't\u2014for example, if you fell and hurt yourself.  But except\nfor these few anomalous cases, work was pretty much defined as\nnot-fun.And it did not seem to be an accident. School, it was implied, was\ntedious because it was preparation for grownup work.The world then was divided into two groups, grownups and kids.\nGrownups, like some kind of cursed race, had to work.  Kids didn't,\nbut they did have to go to school, which was a dilute version of\nwork meant to prepare us for the real thing.  Much as we disliked\nschool, the grownups all agreed that grownup work was worse, and\nthat we had it easy.Teachers in particular all seemed to believe implicitly that work\nwas not fun.  Which is not surprising: work wasn't fun for most of\nthem.  Why did we have to memorize state capitals instead of playing\ndodgeball?  For the same reason they had to watch over a bunch of\nkids instead of lying on a beach.  You couldn't just do what you\nwanted.I'm not saying we should let little kids do whatever they want.\nThey may have to be made to work on certain things.  But if we make\nkids work on dull stuff, it might be wise to tell them that tediousness\nis not the defining quality of work, and indeed that the reason\nthey have to work on dull stuff now is so they can work on more\ninteresting stuff later.\n[1]Once, when I was about 9 or 10, my father told me I could be whatever\nI wanted when I grew up, so long as I enjoyed it.  I remember that\nprecisely because it seemed so anomalous.  It was like being told\nto use dry water.  Whatever I thought he meant, I didn't think he\nmeant work could literally be fun\u2014fun like playing.  It\ntook me years to grasp that.JobsBy high school, the prospect of an actual job was on the horizon.\nAdults would sometimes come to speak to us about their work, or we\nwould go to see them at work.  It was always understood that they\nenjoyed what they did.  In retrospect I think one may have: the\nprivate jet pilot.  But I don't think the bank manager really did.The main reason they all acted as if they enjoyed their work was\npresumably the upper-middle class convention that you're supposed\nto.  It would not merely be bad for your career to say that you\ndespised your job, but a social faux-pas.Why is it conventional to pretend to like what you do?  The first\nsentence of this essay explains that.  If you have to like something\nto do it well, then the most successful people will all like what\nthey do.  That's where the upper-middle class tradition comes from.\nJust as houses all over America are full of \nchairs\nthat are, without\nthe owners even knowing it, nth-degree imitations of chairs designed\n250 years ago for French kings, conventional attitudes about work\nare, without the owners even knowing it, nth-degree imitations of\nthe attitudes of people who've done great things.What a recipe for alienation.  By the time they reach an age to\nthink about what they'd like to do, most kids have been thoroughly\nmisled about the idea of loving one's work.  School has trained\nthem to regard work as an unpleasant duty.  Having a job is said\nto be even more onerous than schoolwork.  And yet all the adults\nclaim to like what they do.  You can't blame kids for thinking \"I\nam not like these people; I am not suited to this world.\"Actually they've been told three lies: the stuff they've been taught\nto regard as work in school is not real work; grownup work is not\n(necessarily) worse than schoolwork; and many of the adults around\nthem are lying when they say they like what they do.The most dangerous liars can be the kids' own parents.  If you take\na boring job to give your family a high standard of living, as so\nmany people do, you risk infecting your kids with the idea that\nwork is boring. \n[2]\nMaybe it would be better for kids in this one\ncase if parents were not so unselfish.  A parent who set an example\nof loving their work might help their kids more than an expensive\nhouse.\n[3]It was not till I was in college that the idea of work finally broke\nfree from the idea of making a living.  Then the important question\nbecame not how to make money, but what to work on.  Ideally these\ncoincided, but some spectacular boundary cases (like Einstein in\nthe patent office) proved they weren't identical.The definition of work was now to make some original contribution\nto the world, and in the process not to starve.  But after the habit\nof so many years my idea of work still included a large component\nof pain.  Work still seemed to require discipline, because only\nhard problems yielded grand results, and hard problems couldn't\nliterally be fun.   Surely one had to force oneself to work on them.If you think something's supposed to hurt, you're less likely to\nnotice if you're doing it wrong.  That about sums up my experience\nof graduate school.BoundsHow much are you supposed to like what you do?  Unless you\nknow that, you don't know when to stop searching. And if, like most\npeople, you underestimate it, you'll tend to stop searching too\nearly.  You'll end up doing something chosen for you by your parents,\nor the desire to make money, or prestige\u2014or sheer inertia.Here's an upper bound: Do what you love doesn't mean, do what you\nwould like to do most this second.  Even Einstein probably\nhad moments when he wanted to have a cup of coffee, but told himself\nhe ought to finish what he was working on first.It used to perplex me when I read about people who liked what they\ndid so much that there was nothing they'd rather do.  There didn't\nseem to be any sort of work I liked that much.  If I had a\nchoice of (a) spending the next hour working on something or (b)\nbe teleported to Rome and spend the next hour wandering about, was\nthere any sort of work I'd prefer?  Honestly, no.But the fact is, almost anyone would rather, at any given moment,\nfloat about in the Carribbean, or have sex, or eat some delicious\nfood, than work on hard problems.  The rule about doing what you\nlove assumes a certain length of time.  It doesn't mean, do what\nwill make you happiest this second, but what will make you happiest\nover some longer period, like a week or a month.Unproductive pleasures pall eventually.  After a while you get tired\nof lying on the beach.  If you want to stay happy, you have to do\nsomething.As a lower bound, you have to like your work more than any unproductive\npleasure.  You have to like what you do enough that the concept of\n\"spare time\" seems mistaken.  Which is not to say you have to spend\nall your time working.  You can only work so much before you get\ntired and start to screw up.  Then you want to do something else\u2014even something mindless.  But you don't regard this time as the\nprize and the time you spend working as the pain you endure to earn\nit.I put the lower bound there for practical reasons.  If your work\nis not your favorite thing to do, you'll have terrible problems\nwith procrastination.  You'll have to force yourself to work,  and\nwhen you resort to that the results are distinctly inferior.To be happy I think you have to be doing something you not only\nenjoy, but admire.  You have to be able to say, at the end, wow,\nthat's pretty cool.  This doesn't mean you have to make something.\nIf you learn how to hang glide, or to speak a foreign language\nfluently, that will be enough to make you say, for a while at least,\nwow, that's pretty cool.  What there has to be is a test.So one thing that falls just short of the standard, I think, is\nreading books.  Except for some books in math and the hard sciences,\nthere's no test of how well you've read a book, and that's why\nmerely reading books doesn't quite feel like work.  You have to do\nsomething with what you've read to feel productive.I think the best test is one Gino Lee taught me: to try to do things\nthat would make your friends say wow.  But it probably wouldn't\nstart to work properly till about age 22, because most people haven't\nhad a big enough sample to pick friends from before then.SirensWhat you should not do, I think, is worry about the opinion of\nanyone beyond your friends.  You shouldn't worry about prestige.\nPrestige is the opinion of the rest of the world.  When you can ask\nthe opinions of people whose judgement you respect, what does it\nadd to consider the opinions of people you don't even know? \n[4]This is easy advice to give.  It's hard to follow, especially when\nyou're young.  \n[5]\nPrestige is like a powerful magnet that warps\neven your beliefs about what you enjoy.  It causes you to work not\non what you like, but what you'd like to like.That's what leads people to try to write novels, for example.  They\nlike reading novels.  They notice that people who write them win\nNobel prizes.  What could be more wonderful, they think, than to\nbe a novelist?  But liking the idea of being a novelist is not\nenough; you have to like the actual work of novel-writing if you're\ngoing to be good at it; you have to like making up elaborate lies.Prestige is just fossilized inspiration.  If you do anything well\nenough, you'll make it prestigious.  Plenty of things we now\nconsider prestigious were anything but at first.  Jazz comes to\nmind\u2014though almost any established art form would do.   So just\ndo what you like, and let prestige take care of itself.Prestige is especially dangerous to the ambitious.  If you want to\nmake ambitious people waste their time on errands, the way to do\nit is to bait the hook with prestige.  That's the recipe for getting\npeople to give talks, write forewords, serve on committees, be\ndepartment heads, and so on.  It might be a good rule simply to\navoid any prestigious task. If it didn't suck, they wouldn't have\nhad to make it prestigious.Similarly, if you admire two kinds of work equally, but one is more\nprestigious, you should probably choose the other.  Your opinions\nabout what's admirable are always going to be slightly influenced\nby prestige, so if the two seem equal to you, you probably have\nmore genuine admiration for the less prestigious one.The other big force leading people astray is money.  Money by itself\nis not that dangerous.  When something pays well but is regarded\nwith contempt, like telemarketing, or prostitution, or personal\ninjury litigation, ambitious people aren't tempted by it.  That\nkind of work ends up being done by people who are \"just trying to\nmake a living.\"  (Tip: avoid any field whose practitioners say\nthis.)  The danger is when money is combined with prestige, as in,\nsay, corporate law, or medicine.  A comparatively safe and prosperous\ncareer with some automatic baseline prestige is dangerously tempting\nto someone young, who hasn't thought much about what they really\nlike.The test of whether people love what they do is whether they'd do\nit even if they weren't paid for it\u2014even if they had to work at\nanother job to make a living.  How many corporate lawyers would do\ntheir current work if they had to do it for free, in their spare\ntime, and take day jobs as waiters to support themselves?This test is especially helpful in deciding between different kinds\nof academic work, because fields vary greatly in this respect.  Most\ngood mathematicians would work on math even if there were no jobs\nas math professors, whereas in the departments at the other end of\nthe spectrum, the availability of teaching jobs is the driver:\npeople would rather be English professors than work in ad agencies,\nand publishing papers is the way you compete for such jobs.  Math\nwould happen without math departments, but it is the existence of\nEnglish majors, and therefore jobs teaching them, that calls into\nbeing all those thousands of dreary papers about gender and identity\nin the novels of Conrad.  No one does \nthat \nkind of thing for fun.The advice of parents will tend to err on the side of money.  It\nseems safe to say there are more undergrads who want to be novelists\nand whose parents want them to be doctors than who want to be doctors\nand whose parents want them to be novelists.  The kids think their\nparents are \"materialistic.\" Not necessarily.  All parents tend to\nbe more conservative for their kids than they would for themselves,\nsimply because, as parents, they share risks more than rewards.  If\nyour eight year old son decides to climb a tall tree, or your teenage\ndaughter decides to date the local bad boy, you won't get a share\nin the excitement, but if your son falls, or your daughter gets\npregnant, you'll have to deal with the consequences.DisciplineWith such powerful forces leading us astray, it's not surprising\nwe find it so hard to discover what we like to work on.  Most people\nare doomed in childhood by accepting the axiom that work = pain.\nThose who escape this are nearly all lured onto the rocks by prestige\nor money.  How many even discover something they love to work on?\nA few hundred thousand, perhaps, out of billions.It's hard to find work you love; it must be, if so few do.  So don't\nunderestimate this task.  And don't feel bad if you haven't succeeded\nyet.  In fact, if you admit to yourself that you're discontented,\nyou're a step ahead of most people, who are still in denial.  If\nyou're surrounded by colleagues who claim to enjoy work that you\nfind contemptible, odds are they're lying to themselves.  Not\nnecessarily, but probably.Although doing great work takes less discipline than people think\u2014because the way to do great work is to find something you like so\nmuch that you don't have to force yourself to do it\u2014finding\nwork you love does usually require discipline.   Some people are\nlucky enough to know what they want to do when they're 12, and just\nglide along as if they were on railroad tracks.  But this seems the\nexception.  More often people who do great things have careers with\nthe trajectory of a ping-pong ball.  They go to school to study A,\ndrop out and get a job doing B, and then become famous for C after\ntaking it up on the side.Sometimes jumping from one sort of work to another is a sign of\nenergy, and sometimes it's a sign of laziness.  Are you dropping\nout, or boldly carving a new path?  You often can't tell yourself.\nPlenty of people who will later do great things seem to be disappointments\nearly on, when they're trying to find their niche.Is there some test you can use to keep yourself honest?  One is to\ntry to do a good job at whatever you're doing, even if you don't\nlike it.  Then at least you'll know you're not using dissatisfaction\nas an excuse for being lazy.  Perhaps more importantly, you'll get\ninto the habit of doing things well.Another test you can use is: always produce.  For example, if you\nhave a day job you don't take seriously because you plan to be a\nnovelist, are you producing?  Are you writing pages of fiction,\nhowever bad?  As long as you're producing, you'll know you're not\nmerely using the hazy vision of the grand novel you plan to write\none day as an opiate.  The view of it will be obstructed by the all\ntoo palpably flawed one you're actually writing.\"Always produce\" is also a heuristic for finding the work you love.\nIf you subject yourself to that constraint, it will automatically\npush you away from things you think you're supposed to work on,\ntoward things you actually like.  \"Always produce\" will discover\nyour life's work the way water, with the aid of gravity, finds the\nhole in your roof.Of course, figuring out what you like to work on doesn't mean you\nget to work on it.  That's a separate question.  And if you're\nambitious you have to keep them separate: you have to make a conscious\neffort to keep your ideas about what you want from being contaminated\nby what seems possible. \n[6]It's painful to keep them apart, because it's painful to observe\nthe gap between them. So most people pre-emptively lower their\nexpectations.  For example, if you asked random people on the street\nif they'd like to be able to draw like Leonardo, you'd find most\nwould say something like \"Oh, I can't draw.\"  This is more a statement\nof intention than fact; it means, I'm not going to try.  Because\nthe fact is, if you took a random person off the street and somehow\ngot them to work as hard as they possibly could at drawing for the\nnext twenty years, they'd get surprisingly far.  But it would require\na great moral effort; it would mean staring failure in the eye every\nday for years.  And so to protect themselves people say \"I can't.\"Another related line you often hear is that not everyone can do\nwork they love\u2014that someone has to do the unpleasant jobs.  Really?\nHow do you make them?  In the US the only mechanism for forcing\npeople to do unpleasant jobs is the draft, and that hasn't been\ninvoked for over 30 years.  All we can do is encourage people to\ndo unpleasant work, with money and prestige.If there's something people still won't do, it seems as if society\njust has to make do without.  That's what happened with domestic\nservants.  For millennia that was the canonical example of a job\n\"someone had to do.\"  And yet in the mid twentieth century servants\npractically disappeared in rich countries, and the rich have just\nhad to do without.So while there may be some things someone has to do, there's a good\nchance anyone saying that about any particular job is mistaken.\nMost unpleasant jobs would either get automated or go undone if no\none were willing to do them.Two RoutesThere's another sense of \"not everyone can do work they love\"\nthat's all too true, however.  One has to make a living, and it's\nhard to get paid for doing work you love.  There are two routes to\nthat destination:\n\n  The organic route: as you become more eminent, gradually to\n  increase the parts of your job that you like at the expense of\n  those you don't.The two-job route: to work at things you don't like to get money\n  to work on things you do.\n\nThe organic route is more common.  It happens naturally to anyone\nwho does good work.  A young architect has to take whatever work\nhe can get, but if he does well he'll gradually be in a position\nto pick and choose among projects.  The disadvantage of this route\nis that it's slow and uncertain.  Even tenure is not real freedom.The two-job route has several variants depending on how long you\nwork for money at a time.  At one extreme is the \"day job,\" where\nyou work regular hours at one job to make money, and work on what\nyou love in your spare time.  At the other extreme you work at\nsomething till you make enough not to \nhave to work for money again.The two-job route is less common than the organic route, because\nit requires a deliberate choice.  It's also more dangerous.  Life\ntends to get more expensive as you get older, so it's easy to get\nsucked into working longer than you expected at the money job.\nWorse still, anything you work on changes you.  If you work too\nlong on tedious stuff, it will rot your brain.  And the best paying\njobs are most dangerous, because they require your full attention.The advantage of the two-job route is that it lets you jump over\nobstacles.  The landscape of possible jobs isn't flat; there are\nwalls of varying heights between different kinds of work. \n[7]\nThe trick of maximizing the parts of your job that you like can get you\nfrom architecture to product design, but not, probably, to music.\nIf you make money doing one thing and then work on another, you\nhave more freedom of choice.Which route should you take?  That depends on how sure you are of\nwhat you want to do, how good you are at taking orders, how much\nrisk you can stand, and the odds that anyone will pay (in your\nlifetime) for what you want to do.  If you're sure of the general\narea you want to work in and it's something people are likely to\npay you for, then you should probably take the organic route.  But\nif you don't know what you want to work on, or don't like to take\norders, you may want to take the two-job route, if you can stand\nthe risk.Don't decide too soon.  Kids who know early what they want to do\nseem impressive, as if they got the answer to some math question\nbefore the other kids.  They have an answer, certainly, but odds\nare it's wrong.A friend of mine who is a quite successful doctor complains constantly\nabout her job.  When people applying to medical school ask her for\nadvice, she wants to shake them and yell \"Don't do it!\"  (But she\nnever does.) How did she get into this fix?  In high school she\nalready wanted to be a doctor.  And she is so ambitious and determined\nthat she overcame every obstacle along the way\u2014including,\nunfortunately, not liking it.Now she has a life chosen for her by a high-school kid.When you're young, you're given the impression that you'll get\nenough information to make each choice before you need to make it.\nBut this is certainly not so with work.  When you're deciding what\nto do, you have to operate on ridiculously incomplete information.\nEven in college you get little idea what various types of work are\nlike.  At best you may have a couple internships, but not all jobs\noffer internships, and those that do don't teach you much more about\nthe work than being a batboy teaches you about playing baseball.In the design of lives, as in the design of most other things, you\nget better results if you use flexible media.  So unless you're\nfairly sure what you want to do, your best bet may be to choose a\ntype of work that could turn into either an organic or two-job\ncareer.  That was probably part of the reason I chose computers.\nYou can be a professor, or make a lot of money, or morph it into\nany number of other kinds of work.It's also wise, early on, to seek jobs that let you do many different\nthings, so you can learn faster what various kinds of work are like.\nConversely, the extreme version of the two-job route is dangerous\nbecause it teaches you so little about what you like.  If you work\nhard at being a bond trader for ten years, thinking that you'll\nquit and write novels when you have enough money, what happens when\nyou quit and then discover that you don't actually like writing\nnovels?Most people would say, I'd take that problem.  Give me a million\ndollars and I'll figure out what to do.  But it's harder than it\nlooks.  Constraints give your life shape.  Remove them and most\npeople have no idea what to do: look at what happens to those who\nwin lotteries or inherit money.  Much as everyone thinks they want\nfinancial security, the happiest people are not those who have it,\nbut those who like what they do.  So a plan that promises freedom\nat the expense of knowing what to do with it may not be as good as\nit seems.Whichever route you take, expect a struggle.  Finding work you love\nis very difficult.  Most people fail.  Even if you succeed, it's\nrare to be free to work on what you want till your thirties or\nforties.  But if you have the destination in sight you'll be more\nlikely to arrive at it.  If you know you can love work, you're in\nthe home stretch, and if you know what work you love, you're\npractically there.Notes[1]\nCurrently we do the opposite: when we make kids do boring work,\nlike arithmetic drills, instead of admitting frankly that it's\nboring, we try to disguise it with superficial decorations.[2]\nOne father told me about a related phenomenon: he found himself\nconcealing from his family how much he liked his work.  When he\nwanted to go to work on a saturday, he found it easier to say that\nit was because he \"had to\" for some reason, rather than admitting\nhe preferred to work than stay home with them.[3]\nSomething similar happens with suburbs.  Parents move to suburbs\nto raise their kids in a safe environment, but suburbs are so dull\nand artificial that by the time they're fifteen the kids are convinced\nthe whole world is boring.[4]\nI'm not saying friends should be the only audience for your\nwork.  The more people you can help, the better.  But friends should\nbe your compass.[5]\nDonald Hall said young would-be poets were mistaken to be so\nobsessed with being published.  But you can imagine what it would\ndo for a 24 year old to get a poem published in The New Yorker.\nNow to people he meets at parties he's a real poet.  Actually he's\nno better or worse than he was before, but to a clueless audience\nlike that, the approval of an official authority makes all the\ndifference.   So it's a harder problem than Hall realizes.  The\nreason the young care so much about prestige is that the people\nthey want to impress are not very discerning.[6]\nThis is isomorphic to the principle that you should prevent\nyour beliefs about how things are from being contaminated by how\nyou wish they were.  Most people let them mix pretty promiscuously.\nThe continuing popularity of religion is the most visible index of\nthat.[7]\nA more accurate metaphor would be to say that the graph of jobs\nis not very well connected.Thanks to Trevor Blackwell, Dan Friedman, Sarah Harlin,\nJessica Livingston, Jackie McDonough, Robert Morris, Peter Norvig, \nDavid Sloo, and Aaron Swartz\nfor reading drafts of this.August 2021When people say that in their experience all programming languages\nare basically equivalent, they're making a statement not about\nlanguages but about the kind of programming they've done.99.5% of programming consists of gluing together calls to library\nfunctions. All popular languages are equally good at this. So one\ncan easily spend one's whole career operating in the intersection\nof popular programming languages.But the other .5% of programming is disproportionately interesting.\nIf you want to learn what it consists of, the weirdness of weird\nlanguages is a good clue to follow.Weird languages aren't weird by accident. Not the good ones, at\nleast. The weirdness of the good ones usually implies the existence\nof some form of programming that's not just the usual gluing together\nof library calls.A concrete example: Lisp macros. Lisp macros seem weird even to\nmany Lisp programmers. They're not only not in the intersection of\npopular languages, but by their nature would be hard to implement\nproperly in a language without turning it into a dialect of\nLisp. And macros are definitely evidence of techniques that go\nbeyond glue programming. For example, solving problems by first\nwriting a language for problems of that type, and then writing\nyour specific application in it. Nor is this all you can do with\nmacros; it's just one region in a space of program-manipulating\ntechniques that even now is far from fully explored.So if you want to expand your concept of what programming can be,\none way to do it is by learning weird languages. Pick a language\nthat most programmers consider weird but whose median user is smart,\nand then focus on the differences between this language and the\nintersection of popular languages. What can you say in this language\nthat would be impossibly inconvenient to say in others? In the\nprocess of learning how to say things you couldn't previously say,\nyou'll probably be learning how to think things you couldn't\npreviously think.\nThanks to Trevor Blackwell, Patrick Collison, Daniel Gackle, Amjad\nMasad, and Robert Morris for reading drafts of this.\nApril 2006(This essay is derived from a talk at the 2006 \nStartup School.)The startups we've funded so far are pretty quick, but they seem\nquicker to learn some lessons than others.  I think it's because\nsome things about startups are kind of counterintuitive.We've now \ninvested \nin enough companies that I've learned a trick\nfor determining which points are the counterintuitive ones:\nthey're the ones I have to keep repeating.So I'm going to number these points, and maybe with future startups\nI'll be able to pull off a form of Huffman coding. I'll make them\nall read this, and then instead of nagging them in detail, I'll\njust be able to say: number four!\n1. Release Early.The thing I probably repeat most is this recipe for a startup: get\na version 1 out fast, then improve it based on users' reactions.By \"release early\" I don't mean you should release something full\nof bugs, but that you should release something minimal.  Users hate\nbugs, but they don't seem to mind a minimal version 1, if there's\nmore coming soon.There are several reasons it pays to get version 1 done fast.  One\nis that this is simply the right way to write software, whether for\na startup or not.  I've been repeating that since 1993, and I haven't seen much since to\ncontradict it.  I've seen a lot of startups die because they were\ntoo slow to release stuff, and none because they were too quick.\n[1]One of the things that will surprise you if you build something\npopular is that you won't know your users.  Reddit now has almost half a million\nunique visitors a month.  Who are all those people?  They have no\nidea.  No web startup does.  And since you don't know your users,\nit's dangerous to guess what they'll like.  Better to release\nsomething and let them tell you.Wufoo took this to heart and released\ntheir form-builder before the underlying database.  You can't even\ndrive the thing yet, but 83,000 people came to sit in the driver's\nseat and hold the steering wheel.  And Wufoo got valuable feedback\nfrom it: Linux users complained they used too much Flash, so they\nrewrote their software not to.  If they'd waited to release everything\nat once, they wouldn't have discovered this problem till it was\nmore deeply wired in.Even if you had no users, it would still be important to release\nquickly, because for a startup the initial release acts as a shakedown\ncruise.  If anything major is broken-- if the idea's no good,\nfor example, or the founders hate one another-- the stress of getting\nthat first version out will expose it.  And if you have such problems\nyou want to find them early.Perhaps the most important reason to release early, though, is that\nit makes you work harder.  When you're working on something that\nisn't released, problems are intriguing.  In something that's out\nthere, problems are alarming.  There is a lot more urgency once you\nrelease.  And I think that's precisely why people put it off.  They\nknow they'll have to work a lot harder once they do. \n[2]\n2. Keep Pumping Out Features.Of course, \"release early\" has a second component, without which\nit would be bad advice.  If you're going to start with something\nthat doesn't do much, you better improve it fast.What I find myself repeating is \"pump out features.\"  And this rule\nisn't just for the initial stages.  This is something all startups\nshould do for as long as they want to be considered startups.I don't mean, of course, that you should make your application ever\nmore complex.  By \"feature\" I mean one unit of hacking-- one quantum\nof making users' lives better.As with exercise, improvements beget improvements.  If you run every\nday, you'll probably feel like running tomorrow.  But if you skip\nrunning for a couple weeks, it will be an effort to drag yourself\nout.  So it is with hacking: the more ideas you implement, the more\nideas you'll have.  You should make your system better at least in\nsome small way every day or two.This is not just a good way to get development done; it is also a\nform of marketing.  Users love a site that's constantly improving.\nIn fact, users expect a site to improve.  Imagine if you visited a\nsite that seemed very good, and then returned two months later and\nnot one thing had changed.  Wouldn't it start to seem lame? \n[3]They'll like you even better when you improve in response to their\ncomments, because customers are used to companies ignoring them.\nIf you're the rare exception-- a company that actually listens--\nyou'll generate fanatical loyalty.  You won't need to advertise,\nbecause your users will do it for you.This seems obvious too, so why do I have to keep repeating it?  I\nthink the problem here is that people get used to how things are.\nOnce a product gets past the stage where it has glaring flaws, you\nstart to get used to it, and gradually whatever features it happens\nto have become its identity.  For example, I doubt many people at\nYahoo (or Google for that matter) realized how much better web mail\ncould be till Paul Buchheit showed them.I think the solution is to assume that anything you've made is far\nshort of what it could be.  Force yourself, as a sort of intellectual\nexercise, to keep thinking of improvements.  Ok, sure, what you\nhave is perfect.  But if you had to change something, what would\nit be?If your product seems finished, there are two possible explanations:\n(a) it is finished, or (b) you lack imagination.  Experience suggests\n(b) is a thousand times more likely.\n3. Make Users Happy.Improving constantly is an instance of a more general rule: make\nusers happy.  One thing all startups have in common is that they\ncan't force anyone to do anything.  They can't force anyone to use\ntheir software, and they can't force anyone to do deals with them.\nA startup has to sing for its supper.  That's why the successful\nones make great things.  They have to, or die.When you're running a startup you feel like a little bit of debris\nblown about by powerful winds.  The most powerful wind is users.\nThey can either catch you and loft you up into the sky, as they did\nwith Google, or leave you flat on the pavement, as they do with\nmost startups.  Users are a fickle wind, but more powerful than any\nother.  If they take you up, no competitor can keep you down.As a little piece of debris, the rational thing for you to do is\nnot to lie flat, but to curl yourself into a shape the wind will\ncatch.I like the wind metaphor because it reminds you how impersonal the\nstream of traffic is.  The vast majority of people who visit your\nsite will be casual visitors.  It's them you have to design your\nsite for.  The people who really care will find what they want by\nthemselves.The median visitor will arrive with their finger poised on the Back\nbutton.  Think about your own experience: most links you\nfollow lead to something lame.  Anyone who has used the web for\nmore than a couple weeks has been trained to click on Back after\nfollowing a link.  So your site has to say \"Wait!  Don't click on\nBack.  This site isn't lame.  Look at this, for example.\"There are two things you have to do to make people pause.  The most\nimportant is to explain, as concisely as possible, what the hell\nyour site is about.  How often have you visited a site that seemed\nto assume you already knew what they did?  For example, the corporate\nsite that says the\ncompany makes\n\n  enterprise content management solutions for business that enable\n  organizations to unify people, content and processes to minimize\n  business risk, accelerate time-to-value and sustain lower total\n  cost of ownership.\n\nAn established company may get away with such an opaque description,\nbut no startup can.  A startup\nshould be able to explain in one or two sentences exactly what it\ndoes. \n[4]\nAnd not just to users.  You need this for everyone:\ninvestors, acquirers, partners, reporters, potential employees, and\neven current employees.  You probably shouldn't even start a company\nto do something that can't be described compellingly in one or two\nsentences.The other thing I repeat is to give people everything you've got,\nright away.  If you have something impressive, try to put it on the\nfront page, because that's the only one most visitors will see.\nThough indeed there's a paradox here: the more you push the good\nstuff toward the front, the more likely visitors are to explore\nfurther. \n[5]In the best case these two suggestions get combined: you tell\nvisitors what your site is about by showing them.  One of the\nstandard pieces of advice in fiction writing is \"show, don't tell.\"\nDon't say that a character's angry; have him grind his teeth, or\nbreak his pencil in half.  Nothing will explain what your site does\nso well as using it.The industry term here is \"conversion.\"  The job of your site is\nto convert casual visitors into users-- whatever your definition\nof a user is.  You can measure this in your growth rate.  Either\nyour site is catching on, or it isn't, and you must know which.  If\nyou have decent growth, you'll win in the end, no matter how obscure\nyou are now.  And if you don't, you need to fix something.\n4. Fear the Right Things.Another thing I find myself saying a lot is \"don't worry.\"  Actually,\nit's more often \"don't worry about this; worry about that instead.\"\nStartups are right to be paranoid, but they sometimes fear the wrong\nthings.Most visible disasters are not so alarming as they seem.  Disasters\nare normal in a startup: a founder quits, you discover a patent\nthat covers what you're doing, your servers keep crashing, you run\ninto an insoluble technical problem, you have to change your name,\na deal falls through-- these are all par for the course.  They won't\nkill you unless you let them.Nor will most competitors.  A lot of startups worry \"what if Google\nbuilds something like us?\"  Actually big companies are not the ones\nyou have to worry about-- not even Google.  The people at Google\nare smart, but no smarter than you; they're not as motivated, because\nGoogle is not going to go out of business if this one product fails;\nand even at Google they have a lot of bureaucracy to slow them down.What you should fear, as a startup, is not the established players,\nbut other startups you don't know exist yet.  They're way more\ndangerous than Google because, like you, they're cornered animals.Looking just at existing competitors can give you a false sense of\nsecurity.  You should compete against what someone else could be\ndoing, not just what you can see people doing.  A corollary is that\nyou shouldn't relax just because you have no visible competitors\nyet.  No matter what your idea, there's someone else out there\nworking on the same thing.That's the downside of it being easier to start a startup: more people\nare doing it.  But I disagree with Caterina Fake when she says that\nmakes this a bad time to start a startup.  More people are starting\nstartups, but not as many more as could.  Most college graduates\nstill think they have to get a job.  The average person can't ignore\nsomething that's been beaten into their head since they were three\njust because serving web pages recently got a lot cheaper.And in any case, competitors are not the biggest threat.  Way more\nstartups hose themselves than get crushed by competitors.  There\nare a lot of ways to do it, but the three main ones are internal\ndisputes, inertia, and ignoring users.  Each is, by itself, enough\nto kill you.  But if I had to pick the worst, it would be ignoring\nusers.  If you want a recipe for a startup that's going to die,\nhere it is: a couple of founders who have some great idea they know\neveryone is going to love, and that's what they're going to build,\nno matter what.Almost everyone's initial plan is broken.  If companies stuck to\ntheir initial plans, Microsoft would be selling programming languages,\nand Apple would be selling printed circuit boards.  In both cases\ntheir customers told them what their business should be-- and they\nwere smart enough to listen.As Richard Feynman said, the imagination of nature is greater than\nthe imagination of man.  You'll find more interesting things by\nlooking at the world than you could ever produce just by thinking.\nThis principle is very powerful.  It's why the best abstract painting\nstill falls short of Leonardo, for example.  And it applies to\nstartups too.  No idea for a product could ever be so clever as the\nones you can discover by smashing a beam of prototypes into a beam\nof users.\n5. Commitment Is a Self-Fulfilling Prophecy.I now have enough experience with startups to be able to say what\nthe most important quality is in a startup founder, and it's not\nwhat you might think.  The most important quality in a startup\nfounder is determination.  Not intelligence-- determination.This is a little depressing.  I'd like to believe Viaweb succeeded\nbecause we were smart, not merely determined.  A lot of people in\nthe startup world want to believe that.  Not just founders, but\ninvestors too.  They like the idea of inhabiting a world ruled by\nintelligence.  And you can tell they really believe this, because\nit affects their investment decisions.Time after time VCs invest in startups founded by eminent professors.\nThis may work in biotech, where a lot of startups simply commercialize\nexisting research, but in software you want to invest in students,\nnot professors.  Microsoft, Yahoo, and Google were all founded by\npeople who dropped out of school to do it.  What students lack in\nexperience they more than make up in dedication.Of course, if you want to get rich, it's not enough merely to be\ndetermined.  You have to be smart too, right?  I'd like to think\nso, but I've had an experience that convinced me otherwise: I spent\nseveral years living in New York.You can lose quite a lot in the brains department and it won't kill\nyou.  But lose even a little bit in the commitment department, and\nthat will kill you very rapidly.Running a startup is like walking on your hands: it's possible, but\nit requires extraordinary effort.  If an ordinary employee were\nasked to do the things a startup founder has to, he'd be very\nindignant.  Imagine if you were hired at some big company, and in\naddition to writing software ten times faster than you'd ever had\nto before, they expected you to answer support calls, administer\nthe servers, design the web site, cold-call customers, find the\ncompany office space, and go out and get everyone lunch.And to do all this not in the calm, womb-like atmosphere of a big\ncompany, but against a backdrop of constant disasters.  That's the\npart that really demands determination.  In a startup, there's\nalways some disaster happening.  So if you're the least bit inclined\nto find an excuse to quit, there's always one right there.But if you lack commitment, chances are it will have been hurting\nyou long before you actually quit.  Everyone who deals with startups\nknows how important commitment is, so if they sense you're ambivalent,\nthey won't give you much attention.  If you lack commitment, you'll\njust find that for some mysterious reason good things happen to\nyour competitors but not to you.  If you lack commitment, it will\nseem to you that you're unlucky.Whereas if you're determined to stick around, people will pay\nattention to you, because odds are they'll have to deal with you\nlater.  You're a local, not just a tourist, so everyone has to come\nto terms with you.At Y Combinator we sometimes mistakenly fund teams who have the\nattitude that they're going to give this startup thing a shot for\nthree months, and if something great happens, they'll stick with\nit-- \"something great\" meaning either that someone wants to buy\nthem or invest millions of dollars in them.  But if this is your\nattitude, \"something great\" is very unlikely to happen to you,\nbecause both acquirers and investors judge you by your level of\ncommitment.If an acquirer thinks you're going to stick around no matter what,\nthey'll be more likely to buy you, because if they don't and you\nstick around, you'll probably grow, your price will go up, and\nthey'll be left wishing they'd bought you earlier.  Ditto for\ninvestors.  What really motivates investors, even big VCs, is not\nthe hope of good returns, but the fear of missing out. \n[6]\nSo if\nyou make it clear you're going to succeed no matter what, and the only\nreason you need them is to make it happen a little faster, you're\nmuch more likely to get money.You can't fake this.  The only way to convince everyone that you're\nready to fight to the death is actually to be ready to.You have to be the right kind of determined, though.  I carefully\nchose the word determined rather than stubborn, because stubbornness\nis a disastrous quality in a startup.  You have to be determined,\nbut flexible, like a running back.  A successful running back doesn't\njust put his head down and try to run through people.  He improvises:\nif someone appears in front of him, he runs around them; if someone\ntries to grab him, he spins out of their grip; he'll even run in\nthe wrong direction briefly if that will help.  The one thing he'll\nnever do is stand still. \n[7]\n6. There Is Always Room.I was talking recently to a startup founder about whether it might\nbe good to add a social component to their software.  He said he\ndidn't think so, because the whole social thing was tapped out.\nReally?  So in a hundred years the only social networking sites\nwill be the Facebook, MySpace, Flickr, and Del.icio.us?  Not likely.There is always room for new stuff.  At every point in history,\neven the darkest bits of the dark ages, people were discovering\nthings that made everyone say \"why didn't anyone think of that\nbefore?\"  We know this continued to be true up till 2004, when the\nFacebook was founded-- though strictly speaking someone else did\nthink of that.The reason we don't see the opportunities all around us is that we\nadjust to however things are, and assume that's how things have to\nbe.  For example, it would seem crazy to most people to try to make\na better search engine than Google.  Surely that field, at least,\nis tapped out.  Really?  In a hundred years-- or even twenty-- are\npeople still going to search for information using something like\nthe current Google?  Even Google probably doesn't think that.In particular, I don't think there's any limit to the number of\nstartups.  Sometimes you hear people saying \"All these guys starting\nstartups now are going to be disappointed. How many little startups\nare Google and Yahoo going to buy, after all?\" That sounds cleverly\nskeptical, but I can prove it's mistaken.  No one proposes that\nthere's some limit to the number of people who can be employed in\nan economy consisting of big, slow-moving companies with a couple\nthousand people each.  Why should there be any limit to the number\nwho could be employed by small, fast-moving companies with ten each?\nIt seems to me the only limit would be the number of people who\nwant to work that hard.The limit on the number of startups is not the number that can get\nacquired by Google and Yahoo-- though it seems even that should\nbe unlimited, if the startups were actually worth buying-- but the\namount of wealth that can be created.  And I don't think there's\nany limit on that, except cosmological ones.So for all practical purposes, there is no limit to the number of\nstartups.  Startups make wealth, which means they make things people\nwant, and if there's a limit on the number of things people want,\nwe are nowhere near it.  I still don't even have a flying car.\n7. Don't Get Your Hopes Up.This is another one I've been repeating since long before Y Combinator.\nIt was practically the corporate motto at Viaweb.Startup founders are naturally optimistic.  They wouldn't do it\notherwise.  But you should treat your optimism the way you'd treat\nthe core of a nuclear reactor: as a source of power that's also\nvery dangerous.  You have to build a shield around it, or it will\nfry you.The shielding of a reactor is not uniform; the reactor would be\nuseless if it were.  It's pierced in a few places to let pipes in.\nAn optimism shield has to be pierced too.  I think the place to\ndraw the line is between what you expect of yourself, and what you\nexpect of other people.  It's ok to be optimistic about what you\ncan do, but assume the worst about machines and other people.This is particularly necessary in a startup, because you tend to\nbe pushing the limits of whatever you're doing.  So things don't\nhappen in the smooth, predictable way they do in the rest of the\nworld.  Things change suddenly, and usually for the worse.Shielding your optimism is nowhere more important than with deals.\nIf your startup is doing a deal, just assume it's not going to\nhappen.  The VCs who say they're going to invest in you aren't.\nThe company that says they're going to buy you isn't.  The big\ncustomer who wants to use your system in their whole company won't.\nThen if things work out you can be pleasantly surprised.The reason I warn startups not to get their hopes up is not to save\nthem from being disappointed when things fall through.  It's\nfor a more practical reason: to prevent them from leaning their\ncompany against something that's going to fall over, taking them\nwith it.For example, if someone says they want to invest in you, there's a\nnatural tendency to stop looking for other investors.  That's why\npeople proposing deals seem so positive: they want you to\nstop looking.  And you want to stop too, because doing deals is a\npain.  Raising money, in particular, is a huge time sink.  So you\nhave to consciously force yourself to keep looking.Even if you ultimately do the first deal, it will be to your advantage\nto have kept looking, because you'll get better terms.  Deals are\ndynamic; unless you're negotiating with someone unusually honest,\nthere's not a single point where you shake hands and the deal's\ndone. There are usually a lot of subsidiary questions to be cleared\nup after the handshake, and if the other side senses weakness-- if\nthey sense you need this deal-- they will be very tempted to screw\nyou in the details.VCs and corp dev guys are professional negotiators.  They're trained\nto take advantage of weakness. \n[8]\nSo while they're often nice\nguys, they just can't help it.  And as pros they do this more than\nyou.  So don't even try to bluff them.  The only way a startup can\nhave any leverage in a deal is genuinely not to need it.  And if\nyou don't believe in a deal, you'll be less likely to depend on it.So I want to plant a hypnotic suggestion in your heads: when you\nhear someone say the words \"we want to invest in you\" or \"we want\nto acquire you,\" I want the following phrase to appear automatically\nin your head: don't get your hopes up.  Just continue running\nyour company as if this deal didn't exist.  Nothing is more likely\nto make it close.The way to succeed in a startup is to focus on the goal of getting\nlots of users, and keep walking swiftly toward it while investors\nand acquirers scurry alongside trying to wave money in your face.\nSpeed, not MoneyThe way I've described it, starting a startup sounds pretty stressful.\nIt is.  When I talk to the founders of the companies we've funded,\nthey all say the same thing: I knew it would be hard, but I didn't\nrealize it would be this hard.So why do it?  It would be worth enduring a lot of pain and stress\nto do something grand or heroic, but just to make money?  Is making\nmoney really that important?No, not really.  It seems ridiculous to me when people take business\ntoo seriously.  I regard making money as a boring errand to be got\nout of the way as soon as possible.  There is nothing grand or\nheroic about starting a startup per se.So why do I spend so much time thinking about startups?  I'll tell\nyou why.  Economically, a startup is best seen not as a way to get\nrich, but as a way to work faster.  You have to make a living, and\na startup is a way to get that done quickly, instead of letting it\ndrag on through your whole life.\n[9]We take it for granted most of the time, but human life is fairly\nmiraculous.  It is also palpably short.  You're given this marvellous\nthing, and then poof, it's taken away.  You can see why people\ninvent gods to explain it.  But even to people who don't believe\nin gods, life commands respect.  There are times in most of our\nlives when the days go by in a blur, and almost everyone has a\nsense, when this happens, of wasting something precious.  As Ben\nFranklin said, if you love life, don't waste time, because time is\nwhat life is made of.So no, there's nothing particularly grand about making money.  That's\nnot what makes startups worth the trouble.  What's important about\nstartups is the speed.  By compressing the dull but necessary task\nof making a living into the smallest possible time, you show respect\nfor life, and there is something grand about that.Notes[1]\nStartups can die from releasing something full of bugs, and not\nfixing them fast enough, but I don't know of any that died from\nreleasing something stable but minimal very early, then promptly\nimproving it.[2]\nI know this is why I haven't released Arc.  The moment I do,\nI'll have people nagging me for features.[3]\nA web site is different from a book or movie or desktop application\nin this respect.  Users judge a site not as a single snapshot, but\nas an animation with multiple frames.  Of the two, I'd say the rate of\nimprovement is more important to users than where you currently\nare.[4]\nIt should not always tell this to users, however.  For example,\nMySpace is basically a replacement mall for mallrats.  But it was\nwiser for them, initially, to pretend that the site was about bands.[5]\nSimilarly, don't make users register to try your site.  Maybe\nwhat you have is so valuable that visitors should gladly register\nto get at it.  But they've been trained to expect the opposite.\nMost of the things they've tried on the web have sucked-- and\nprobably especially those that made them register.[6]\nVCs have rational reasons for behaving this way. They don't\nmake their money (if they make money) off their median investments.\nIn a typical fund, half the companies fail, most of the rest generate\nmediocre returns, and one or two \"make the fund\" by succeeding\nspectacularly.  So if they miss just a few of the most promising\nopportunities, it could hose the whole fund.[7]\nThe attitude of a running back doesn't translate to soccer.\nThough it looks great when a forward dribbles past multiple defenders,\na player who persists in trying such things will do worse in the\nlong term than one who passes.[8]\nThe reason Y Combinator never negotiates valuations\nis that we're not professional negotiators, and don't want to turn\ninto them.[9]\nThere are two ways to do \nwork you love: (a) to make money, then work\non what you love, or (b) to get a job where you get paid to work on\nstuff you love.  In practice the first phases of both\nconsist mostly of unedifying schleps, and in (b) the second phase is less\nsecure.Thanks to Sam Altman, Trevor Blackwell, Beau Hartshorne, Jessica \nLivingston, and Robert Morris for reading drafts of this.\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nApril 2001, rev. April 2003(This article is derived from a talk given at the 2001 Franz\nDeveloper Symposium.)\nIn the summer of 1995, my friend Robert Morris and I\nstarted a startup called \nViaweb.  \nOur plan was to write\nsoftware that would let end users build online stores.\nWhat was novel about this software, at the time, was\nthat it ran on our server, using ordinary Web pages\nas the interface.A lot of people could have been having this idea at the\nsame time, of course, but as far as I know, Viaweb was\nthe first Web-based application.  It seemed such\na novel idea to us that we named the company after it:\nViaweb, because our software worked via the Web,\ninstead of running on your desktop computer.Another unusual thing about this software was that it\nwas written primarily in a programming language called\nLisp. It was one of the first big end-user\napplications to be written in Lisp, which up till then\nhad been used mostly in universities and research labs. [1]The Secret WeaponEric Raymond has written an essay called \"How to Become a Hacker,\"\nand in it, among other things, he tells would-be hackers what\nlanguages they should learn.  He suggests starting with Python and\nJava, because they are easy to learn.  The serious hacker will also\nwant to learn C, in order to hack Unix, and Perl for system\nadministration and cgi scripts.  Finally, the truly serious hacker\nshould consider learning Lisp:\n\n  Lisp is worth learning for the profound enlightenment experience\n  you will have when you finally get it; that experience will make\n  you a better programmer for the rest of your days, even if you\n  never actually use Lisp itself a lot.\n\nThis is the same argument you tend to hear for learning Latin.  It\nwon't get you a job, except perhaps as a classics professor, but\nit will improve your mind, and make you a better writer in languages\nyou do want to use, like English.But wait a minute.  This metaphor doesn't stretch that far.  The\nreason Latin won't get you a job is that no one speaks it.  If you\nwrite in Latin, no one can understand you.  But Lisp is a computer\nlanguage, and computers speak whatever language you, the programmer,\ntell them to.So if Lisp makes you a better programmer, like he says, why wouldn't\nyou want to use it? If a painter were offered a brush that would\nmake him a better painter, it seems to me that he would want to\nuse it in all his paintings, wouldn't he? I'm not trying to make\nfun of Eric Raymond here.  On the whole, his advice is good.  What\nhe says about Lisp is pretty much the conventional wisdom.  But\nthere is a contradiction in the conventional wisdom:  Lisp will\nmake you a better programmer, and yet you won't use it.Why not?  Programming languages are just tools, after all.  If Lisp\nreally does yield better programs, you should use it.  And if it\ndoesn't, then who needs it?This is not just a theoretical question.  Software is a very\ncompetitive business, prone to natural monopolies.  A company that\ngets software written faster and better will, all other things\nbeing equal, put its competitors out of business.  And when you're\nstarting a startup, you feel this very keenly.  Startups tend to\nbe an all or nothing proposition.  You either get rich, or you get\nnothing.  In a startup, if you bet on the wrong technology, your\ncompetitors will crush you.Robert and I both knew Lisp well, and we couldn't see any reason\nnot to trust our instincts and go with Lisp.  We knew that everyone\nelse was writing their software in C++ or Perl.  But we also knew\nthat that didn't mean anything.  If you chose technology that way,\nyou'd be running Windows.  When you choose technology, you have to\nignore what other people are doing, and consider only what will\nwork the best.This is especially true in a startup.  In a big company, you can\ndo what all the other big companies are doing.  But a startup can't\ndo what all the other startups do.  I don't think a lot of people\nrealize this, even in startups.The average big company grows at about ten percent a year.  So if\nyou're running a big company and you do everything the way the\naverage big company does it, you can expect to do as well as the\naverage big company-- that is, to grow about ten percent a year.The same thing will happen if you're running a startup, of course.\nIf you do everything the way the average startup does it, you should\nexpect average performance.  The problem here is, average performance\nmeans that you'll go out of business.  The survival rate for startups\nis way less than fifty percent.  So if you're running a startup,\nyou had better be doing something odd.  If not, you're in trouble.Back in 1995, we knew something that I don't think our competitors\nunderstood, and few understand even now:  when you're writing\nsoftware that only has to run on your own servers, you can use\nany language you want.  When you're writing desktop software,\nthere's a strong bias toward writing applications in the same\nlanguage as the operating system.  Ten years ago, writing applications\nmeant writing applications in C.  But with Web-based software,\nespecially when you have the source code of both the language and\nthe operating system, you can use whatever language you want.This new freedom is a double-edged sword, however.  Now that you\ncan use any language, you have to think about which one to use.\nCompanies that try to pretend nothing has changed risk finding that\ntheir competitors do not.If you can use any language, which do you use?  We chose Lisp.\nFor one thing, it was obvious that rapid development would be\nimportant in this market.  We were all starting from scratch, so\na company that could get new features done before its competitors\nwould have a big advantage.  We knew Lisp was a really good language\nfor writing software quickly, and server-based applications magnify\nthe effect of rapid development, because you can release software\nthe minute it's done.If other companies didn't want to use Lisp, so much the better.\nIt might give us a technological edge, and we needed all the help\nwe could get.  When we started Viaweb, we had no experience in\nbusiness.  We didn't know anything about marketing, or hiring\npeople, or raising money, or getting customers.  Neither of us had\never even had what you would call a real job.  The only thing we\nwere good at was writing software.  We hoped that would save us.\nAny advantage we could get in the software department, we would\ntake.So you could say that using Lisp was an experiment.  Our hypothesis\nwas that if we wrote our software in Lisp, we'd be able to get\nfeatures done faster than our competitors, and also to do things\nin our software that they couldn't do.  And because Lisp was so\nhigh-level, we wouldn't need a big development team, so our costs\nwould be lower.  If this were so, we could offer a better product\nfor less money, and still make a profit.  We would end up getting\nall the users, and our competitors would get none, and eventually\ngo out of business.  That was what we hoped would happen, anyway.What were the results of this experiment?  Somewhat surprisingly,\nit worked.  We eventually had many competitors, on the order of\ntwenty to thirty of them, but none of their software could compete\nwith ours.  We had a wysiwyg online store builder that ran on the\nserver and yet felt like a desktop application.  Our competitors\nhad cgi scripts.  And we were always far ahead of them in features.\nSometimes, in desperation, competitors would try to introduce\nfeatures that we didn't have.  But with Lisp our development cycle\nwas so fast that we could sometimes duplicate a new feature within\na day or two of a competitor announcing it in a press release.  By\nthe time journalists covering the press release got round to calling\nus, we would have the new feature too.It must have seemed to our competitors that we had some kind of\nsecret weapon-- that we were decoding their Enigma traffic or\nsomething.  In fact we did have a secret weapon, but it was simpler\nthan they realized.  No one was leaking news of their features to\nus.   We were just able to develop software faster than anyone\nthought possible.When I was about nine I happened to get hold of a copy of The Day\nof the Jackal, by Frederick Forsyth.  The main character is an\nassassin who is hired to kill the president of France.  The assassin\nhas to get past the police to get up to an apartment that overlooks\nthe president's route.  He walks right by them, dressed up as an\nold man on crutches, and they never suspect him.Our secret weapon was similar.  We wrote our software in a weird\nAI language, with a bizarre syntax full of parentheses.  For years\nit had annoyed me to hear Lisp described that way.  But now it\nworked to our advantage.  In business, there is nothing more valuable\nthan a technical advantage your competitors don't understand.  In\nbusiness, as in war, surprise is worth as much as force.And so, I'm a little embarrassed to say, I never said anything\npublicly about Lisp while we were working on Viaweb.  We never\nmentioned it to the press, and if you searched for Lisp on our Web\nsite, all you'd find were the titles of two books in my bio.  This\nwas no accident.  A startup should give its competitors as little\ninformation as possible.  If they didn't know what language our\nsoftware was written in, or didn't care, I wanted to keep it that\nway.[2]The people who understood our technology best were the customers.\nThey didn't care what language Viaweb was written in either, but\nthey noticed that it worked really well.  It let them build great\nlooking online stores literally in minutes.  And so, by word of\nmouth mostly, we got more and more users.  By the end of 1996 we\nhad about 70 stores online.  At the end of 1997 we had 500.  Six\nmonths later, when Yahoo bought us, we had 1070 users.  Today, as\nYahoo Store, this software continues to dominate its market.  It's\none of the more profitable pieces of Yahoo, and the stores built\nwith it are the foundation of Yahoo Shopping.  I left Yahoo in\n1999, so I don't know exactly how many users they have now, but\nthe last I heard there were about 20,000.\nThe Blub ParadoxWhat's so great about Lisp?  And if Lisp is so great, why doesn't\neveryone use it?  These sound like rhetorical questions, but actually\nthey have straightforward answers.  Lisp is so great not because\nof some magic quality visible only to devotees, but because it is\nsimply the most powerful language available.  And the reason everyone\ndoesn't use it is that programming languages are not merely\ntechnologies, but habits of mind as well, and nothing changes\nslower.  Of course, both these answers need explaining.I'll begin with a shockingly controversial statement:  programming\nlanguages vary in power.Few would dispute, at least, that high level languages are more\npowerful than machine language.  Most programmers today would agree\nthat you do not, ordinarily, want to program in machine language.\nInstead, you should program in a high-level language, and have a\ncompiler translate it into machine language for you.  This idea is\neven built into the hardware now: since the 1980s, instruction sets\nhave been designed for compilers rather than human programmers.Everyone knows it's a mistake to write your whole program by hand\nin machine language.  What's less often understood is that there\nis a more general principle here: that if you have a choice of\nseveral languages, it is, all other things being equal, a mistake\nto program in anything but the most powerful one. [3]There are many exceptions to this rule.  If you're writing a program\nthat has to work very closely with a program written in a certain\nlanguage, it might be a good idea to write the new program in the\nsame language.  If you're writing a program that only has to do\nsomething very simple, like number crunching or bit manipulation,\nyou may as well use a less abstract language, especially since it\nmay be slightly faster.  And if you're writing a short, throwaway\nprogram, you may be better off just using whatever language has\nthe best library functions for the task.  But in general, for\napplication software, you want to be using the most powerful\n(reasonably efficient) language you can get, and using anything\nelse is a mistake, of exactly the same kind, though possibly in a\nlesser degree, as programming in machine language.You can see that machine language is very low level.  But, at least\nas a kind of social convention, high-level languages are often all\ntreated as equivalent.  They're not.  Technically the term \"high-level\nlanguage\" doesn't mean anything very definite.  There's no dividing\nline with machine languages on one side and all the high-level\nlanguages on the other.  Languages fall along a continuum [4] of\nabstractness, from the most powerful all the way down to machine\nlanguages, which themselves vary in power.Consider Cobol.  Cobol is a high-level language, in the sense that\nit gets compiled into machine language.  Would anyone seriously\nargue that Cobol is equivalent in power to, say, Python?  It's\nprobably closer to machine language than Python.Or how about Perl 4?  Between Perl 4 and Perl 5, lexical closures\ngot added to the language.  Most Perl hackers would agree that Perl\n5 is more powerful than Perl 4.  But once you've admitted that,\nyou've admitted that one high level language can be more powerful\nthan another.  And it follows inexorably that, except in special\ncases, you ought to use the most powerful you can get.This idea is rarely followed to its conclusion, though.  After a\ncertain age, programmers rarely switch languages voluntarily.\nWhatever language people happen to be used to, they tend to consider\njust good enough.Programmers get very attached to their favorite languages, and I\ndon't want to hurt anyone's feelings, so to explain this point I'm\ngoing to use a hypothetical language called Blub.  Blub falls right\nin the middle of the abstractness continuum.  It is not the most\npowerful language, but it is more powerful than Cobol or machine\nlanguage.And in fact, our hypothetical Blub programmer wouldn't use either\nof them.  Of course he wouldn't program in machine language.  That's\nwhat compilers are for.  And as for Cobol, he doesn't know how\nanyone can get anything done with it.  It doesn't even have x (Blub\nfeature of your choice).As long as our hypothetical Blub programmer is looking down the\npower continuum, he knows he's looking down.  Languages less powerful\nthan Blub are obviously less powerful, because they're missing some\nfeature he's used to.  But when our hypothetical Blub programmer\nlooks in the other direction, up the power continuum, he doesn't\nrealize he's looking up.  What he sees are merely weird languages.\nHe probably considers them about equivalent in power to Blub, but\nwith all this other hairy stuff thrown in as well.  Blub is good\nenough for him, because he thinks in Blub.When we switch to the point of view of a programmer using any of\nthe languages higher up the power continuum, however, we find that\nhe in turn looks down upon Blub.  How can you get anything done in\nBlub? It doesn't even have y.By induction, the only programmers in a position to see all the\ndifferences in power between the various languages are those who\nunderstand the most powerful one.  (This is probably what Eric\nRaymond meant about Lisp making you a better programmer.) You can't\ntrust the opinions of the others, because of the Blub paradox:\nthey're satisfied with whatever language they happen to use, because\nit dictates the way they think about programs.I know this from my own experience, as a high school kid writing\nprograms in Basic.  That language didn't even support recursion.\nIt's hard to imagine writing programs without using recursion, but\nI didn't miss it at the time.  I thought in Basic.  And I was a\nwhiz at it.  Master of all I surveyed.The five languages that Eric Raymond recommends to hackers fall at\nvarious points on the power continuum.  Where they fall relative\nto one another is a sensitive topic.  What I will say is that I\nthink Lisp is at the top.  And to support this claim I'll tell you\nabout one of the things I find missing when I look at the other\nfour languages.  How can you get anything done in them, I think,\nwithout macros? [5]Many languages have something called a macro.  But Lisp macros are\nunique.  And believe it or not, what they do is related to the\nparentheses.  The designers of Lisp didn't put all those parentheses\nin the language just to be different.  To the Blub programmer, Lisp\ncode looks weird.  But those parentheses are there for a reason.\nThey are the outward evidence of a fundamental difference between\nLisp and other languages.Lisp code is made out of Lisp data objects.  And not in the trivial\nsense that the source files contain characters, and strings are\none of the data types supported by the language.  Lisp code, after\nit's read by the parser, is made of data structures that you can\ntraverse.If you understand how compilers work, what's really going on is\nnot so much that Lisp has a strange syntax as that Lisp has no\nsyntax.  You write programs in the parse trees that get generated\nwithin the compiler when other languages are parsed.  But these\nparse trees are fully accessible to your programs.  You can write\nprograms that manipulate them.  In Lisp, these programs are called\nmacros.  They are programs that write programs.Programs that write programs?  When would you ever want to do that?\nNot very often, if you think in Cobol.  All the time, if you think\nin Lisp.  It would be convenient here if I could give an example\nof a powerful macro, and say there! how about that?  But if I did,\nit would just look like gibberish to someone who didn't know Lisp;\nthere isn't room here to explain everything you'd need to know to\nunderstand what it meant.  In \nAnsi Common Lisp I tried to move\nthings along as fast as I could, and even so I didn't get to macros\nuntil page 160.But I think I can give a kind of argument that might be convincing.\nThe source code of the Viaweb editor was probably about 20-25%\nmacros.  Macros are harder to write than ordinary Lisp functions,\nand it's considered to be bad style to use them when they're not\nnecessary.  So every macro in that code is there because it has to\nbe.  What that means is that at least 20-25% of the code in this\nprogram is doing things that you can't easily do in any other\nlanguage.  However skeptical the Blub programmer might be about my\nclaims for the mysterious powers of Lisp, this ought to make him\ncurious.  We weren't writing this code for our own amusement.  We\nwere a tiny startup, programming as hard as we could in order to\nput technical barriers between us and our competitors.A suspicious person might begin to wonder if there was some\ncorrelation here.  A big chunk of our code was doing things that\nare very hard to do in other languages.  The resulting software\ndid things our competitors' software couldn't do.  Maybe there was\nsome kind of connection.  I encourage you to follow that thread.\nThere may be more to that old man hobbling along on his crutches\nthan meets the eye.Aikido for StartupsBut I don't expect to convince anyone \n(over 25) \nto go out and learn\nLisp.  The purpose of this article is not to change anyone's mind,\nbut to reassure people already interested in using Lisp-- people\nwho know that Lisp is a powerful language, but worry because it\nisn't widely used.  In a competitive situation, that's an advantage.\nLisp's power is multiplied by the fact that your competitors don't\nget it.If you think of using Lisp in a startup, you shouldn't worry that\nit isn't widely understood.  You should hope that it stays that\nway. And it's likely to.  It's the nature of programming languages\nto make most people satisfied with whatever they currently use.\nComputer hardware changes so much faster than personal habits that\nprogramming practice is usually ten to twenty years behind the\nprocessor.  At places like MIT they were writing programs in\nhigh-level languages in the early 1960s, but many companies continued\nto write code in machine language well into the 1980s.  I bet a\nlot of people continued to write machine language until the processor,\nlike a bartender eager to close up and go home, finally kicked them\nout by switching to a risc instruction set.Ordinarily technology changes fast.  But programming languages are\ndifferent: programming languages are not just technology, but what\nprogrammers think in.  They're half technology and half religion.[6]\nAnd so the median language, meaning whatever language the median\nprogrammer uses, moves as slow as an iceberg.  Garbage collection,\nintroduced by Lisp in about 1960, is now widely considered to be\na good thing.  Runtime typing, ditto, is growing in popularity.\nLexical closures, introduced by Lisp in the early 1970s, are now,\njust barely, on the radar screen.  Macros, introduced by Lisp in the\nmid 1960s, are still terra incognita.Obviously, the median language has enormous momentum.  I'm not\nproposing that you can fight this powerful force.  What I'm proposing\nis exactly the opposite: that, like a practitioner of Aikido, you\ncan use it against your opponents.If you work for a big company, this may\n\nRead the document and answer: What is the best thing to do in San Francisco? Here is the most relevant sentence in the context:"}]